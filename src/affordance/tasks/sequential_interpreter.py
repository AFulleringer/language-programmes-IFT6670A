import ast
from dataclasses import dataclass
import re
import subprocess
import sys
import textwrap
import time
from typing import Callable, List, Tuple, Union

import enchant
import openai
import parsimonious
from pot_tools import safe_execute, simplify_ans
import requests
from serpapi import GoogleSearch
from tqdm import tqdm
from utils import Command, OpenAIModel, Program, cleanhtml

subscription_key = "28dc412935f24fb9974d80c30915483a"
search_url = "https://api.bing.microsoft.com/v7.0/search"
headers = {"Ocp-Apim-Subscription-Key": subscription_key}


serp_api_key = "5599fad2263e4b1c6d4efb62fa15f83f5ad2d1bb727b8721d616d719399a7f7b"


def search(query, top_k=1):
    params = {"q": query, "textDecorations": True, "textFormat": "HTML"}
    response = requests.get(search_url, headers=headers, params=params)
    response.raise_for_status()
    search_results = response.json()
    if "webPages" in search_results:
        snippets = [
            cleanhtml(v["name"] + " " + v["snippet"]) for v in search_results["webPages"]["value"]
        ][:top_k]
    else:
        return "", None
    return "\n".join(snippets), None


def google_search(query, previous_input=None, top_k=1):
    params = {
        "q": query,
        #   "location": "Austin, Texas, United States",
        "hl": "en",
        "gl": "us",
        "google_domain": "google.com",
        "api_key": serp_api_key,
    }

    search = GoogleSearch(params)
    try:
        res = search.get_dict()
    except:
        res = {}

    if "answer_box" in res.keys() and "answer" in res["answer_box"].keys():
        toret = res["answer_box"]["answer"]
    elif "answer_box" in res.keys() and "snippet" in res["answer_box"].keys():
        toret = res["answer_box"]["snippet"]
    elif "answer_box" in res.keys() and "snippet_highlighted_words" in res["answer_box"].keys():
        toret = res["answer_box"]["snippet_highlighted_words"][0]
    elif "organic_results" in res.keys() and "snippet" in res["organic_results"][0].keys():
        toret = res["organic_results"][0]["snippet"]
    else:
        toret = None

    return toret, None


def code_generate(instruction, code_input):
    # response = openai.Edit.create(
    # model="code-davinci-edit-001",
    # input="x = " + code_input,
    # instruction="Python code for " + instruction,
    # temperature=0,
    # top_p=1
    # )
    if instruction in code_input:
        # Code input is sufficient to write code
        comment = '"""\n{0}\nStore the final result as a variable named \'ans\' and print it.\n"""\n\n'.format(
            code_input
        )
    else:
        if re.search("#[0-9]+", instruction):
            input_string = re.search("#[0-9]+", instruction).group(0)
            instruction = instruction.replace(input_string, "Input")
        # comment = "\"\"\"\n{0}\nInput:{1}\nStore the final result as a variable named 'ans' and print it.\n\"\"\"\n\ndef".format(instruction, code_input)
        comment = '"""\n{0}\nInput:{1}\nStore the final result as a variable named \'ans\' and print it.\n"""\n\n'.format(
            instruction, code_input
        )

    response = openai.Completion.create(
        # model="code-davinci-002",
        model="davinci-codex-002-msft",
        prompt=comment,
        temperature=0.0,
        max_tokens=256,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        stop=["print(ans)"],
    )

    code_snippet = response.choices[0].text
    time.sleep(5)

    # TODO: Add function run or remove the "def" entirely
    # return "def" + code_snippet, comment
    # if "ans" in code_snippet:
    #     code_snippet += "\nprint(ans)"

    # TODO: Add "print(ans) to the end."
    return code_snippet, comment


def code_execute(code_snippet, code_input=None):
    if code_input:
        try:
            # Run arithmetic python code generate
            code_output = safe_execute(code_input)
            result = simplify_ans(code_output)
            if result:
                return result, code_input
        except:
            pass

    try:
        # Run code snippet as is, if it was generated by code_generate
        # More robust outputs
        result = subprocess.run(
            [sys.executable, "-c", code_input],
            capture_output=True,
            text=True,
            timeout=60,
        )
        if result.stderr == "":
            simplified_result = simplify_ans(result.stdout)
            return simplified_result, code_snippet
    except:
        pass

    try:
        # Run arithmetic python code generate
        code_output = safe_execute(code_snippet)
        result = simplify_ans(code_output)
        if result:
            return result, code_snippet
    except:
        pass

    try:
        # Run code snippet as is, if it was generated by code_generate
        result = subprocess.run(
            [sys.executable, "-c", code_snippet],
            capture_output=True,
            text=True,
            timeout=60,
        )
        if result.stderr == "":
            simplified_result = simplify_ans(result.stdout)
            return simplified_result, code_snippet
    except:
        pass

    if "error" in code_snippet or (code_input and "error" in code_input):
        return code_error(code_snippet, code_input)

    try:
        # Command instruction (if its code) starts in the next line.
        code_snippet = code_snippet.split("\n", 1)[1]
        result = subprocess.run(
            [sys.executable, "-c", code_snippet],
            capture_output=True,
            text=True,
            timeout=60,
        )
        if result.stderr == "":
            simplified_result = simplify_ans(result.stdout)
            return simplified_result, code_snippet
    except:
        return None, code_snippet

    return None, code_snippet


def code_generate_then_execute(instruction, code_input):
    # output = openai.Edit.create(
    # model="code-davinci-edit-001",
    # input="x = " + code_input,
    # instruction="Python code for " + instruction,
    # temperature=0,
    # top_p=1
    # )
    # code_snippet = output.choices[0].text

    code_snippet, generate_details = code_generate(instruction=instruction, code_input=code_input)
    time.sleep(2)
    # result = subprocess.run([sys.executable, "-c", code_snippet], capture_output=True, text=True)
    # if result.stderr == "":
    #     return result.stdout, code_snippet
    result = code_execute(code_snippet=code_snippet)
    return result


def code_error(code_snippet, code_input):
    # Command instruction (if its code) starts in the next line.
    try:
        code_snippet = code_snippet.split("\n", 1)[1]
        result = subprocess.run(
            [sys.executable, "-c", code_snippet],
            capture_output=True,
            text=True,
            timeout=60,
        )
        if result.stderr != "":
            return result.stderr, code_snippet
    except:
        return None, code_snippet


def code_edit(instruction, code_input):
    comment = "# " + instruction + "\n"
    response = openai.Completion.create(
        # model="code-davinci-002",
        model="davinci-codex-002-msft",
        prompt=comment,
        temperature=0.0,
        max_tokens=256,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        stop=["\n"],
    )

    code_snippet = response.choices[0].text
    return comment + code_snippet, comment


def code_generate_then_lookup(instruction, code_input):
    code_snippet, generate_details = code_generate(instruction=instruction, code_input=code_input)
    time.sleep(2)
    result, execute_snippet = code_execute(code_snippet=code_snippet)
    d = enchant.Dict("en_US")
    try:
        word_list = ["".join(chat_list) for chat_list in ast.literal_eval(result)]
        valid_list = []
        for word in word_list:
            if d.check(word):
                valid_list.append(word)
        return simplify_ans(valid_list), execute_snippet
    except:
        return None, execute_snippet


def lookup(word_list):
    d = enchant.Dict("en_US")
    valid_list = []
    for word in word_list:
        if d.check(word):
            valid_list.append(word)
    return valid_list


def arithmetic(equations, previous_input):
    # collect all outputs of arithmetic and run python to execute them
    result = subprocess.run(
        [sys.executable, "-c", "\n".join(equations)], capture_output=True, text=True
    )
    return result, None


_gpt3 = OpenAIModel(model="text-davinci-002", max_length=200, quote="", n=1)


def generate(prompt, previous_input):
    return _gpt3(prompt)[0], None


def trim_demonstrations(s: str) -> str:
    """Trim the few-shot demonstrations from prompt text."""
    return s.rsplit("----\n", 1)[1].split("\n", 1)[1]


@dataclass
class StacktraceItem:
    command: Command
    tool: str
    tool_output: str
    tool_details: str
    rerun_program: str
    rerun_program_parsed: Program


class TopDownVisitor:
    def __init__(
        self,
        model_name: str = "text-davinci-002",
        temperature: float = 0.3,
        rerun: bool = True,
        exclude_list: List[str] = [],
    ):
        self.built_ins = {
            "[generate]": generate,
            "[search]": google_search,
            "[code generate]": code_generate,
            "[code execute]": code_execute,
            "[code edit]": code_edit,
            "[string edit]": code_generate_then_execute,
            "[string index]": code_generate_then_execute,
            "[string permutation]": code_generate_then_lookup,
            "[arithmetic]": arithmetic,
            "[generate python code]": code_generate,
        }
        for key in exclude_list:
            del self.built_ins[key]
        self.keyword_map = {
            "[permutation]": "[string permutation]",
            "[permute]": "[string permutation]",
            "[string permute]": "[string permutation]",
            "[execute]": "[code execute]",
        }

        self.execution_details: List[StacktraceItem] = []
        self.rerun = rerun
        self.program_completer = OpenAIModel(
            model_name, quote="---", temperature=temperature, max_length=500, n=1
        )

    @staticmethod
    def program_ends(program: str) -> bool:
        """Return true if the program contains [EOQ] and a final answer."""
        return "[EOQ]\nAns:" in program

    def batch_visit(self, prefixes: List[str], programs: List[str]) -> List[str]:
        answers = []
        for prefix, program in tqdm(zip(prefixes, programs)):
            answers.append(self.visit(prefix, program))
        return answers

    def get_builtin(self, command: str) -> Union[Callable[[str, str], Tuple[str, str]], None]:
        """Get the tool function from its name (or an alias in self.keyword_map).

        Returns None if not found."""
        if command in self.built_ins:
            return self.built_ins[command]
        if command in self.keyword_map:
            return self.built_ins[self.keyword_map[command]]

        return None

    def shorten_prefix(self, prefix: str, to_remove: int) -> str:
        """Remove few-shot examples from the prefix, starting with the latter ones.

        We start with the latter ones in case they're organized by task relevance.
        """
        # split along demonstrations
        individual_programs = prefix.split("\n----\n")

        shifted_programs = individual_programs[: -(to_remove + 1)] + [individual_programs[-1]]

        return "\n----\n".join(shifted_programs)

    def complete_program(self, prefix: str, program: str, runs: int = 5):
        separator = "\nQ"

        for _ in range(runs):
            if self.program_ends(program):
                break

            # shift window on few-shot demonstrations
            prefix = self.shorten_prefix(prefix, 1)

            # TODO: explicitly check if the program ends in answers or questions and accordingly
            # change the separator

            program += separator + self.program_completer(prefix + program + separator)[0]

        return program

    def rerun_program(
        self, prefix: str, prev_commands: List[Command], current_output: str
    ) -> Tuple[str, str]:
        # recreate the program string up to the current command
        prefix += "\n".join(c.to_program_chunk(i + 1) for i, c in enumerate(prev_commands[:-1]))
        if prefix:
            prefix += "\n"

        # recreate the input text of the current command
        prefix += prev_commands[-1].to_program_chunk(len(prev_commands), input_only=True)
        output_sep = "\n" if "\n" in current_output else " "
        prefix += f"\n#{len(prev_commands)}:{output_sep}{current_output.strip()}\nQ"

        # get corrected output
        continuation = self.program_completer(prefix)[0]

        return prefix, continuation

    def rerun_answer(self, prefix: str) -> str:
        return self.program_completer(prefix)[0]

    def visit(self, prefix: str, program: str) -> str:
        # check if the program ends with an answer
        program_ends = self.program_ends(program)

        # The prompt contains the beginning of the program, so we'll prepend it to the program.
        program = trim_demonstrations(prefix) + program

        # print for debugging purposes
        print("visiting program:")
        print(textwrap.indent(program, "  "))
        print("program_ends:", program_ends)

        # If the program does not end completely, run further to end it.
        if not program_ends:
            new_program = self.complete_program(prefix, program)
            if not self.program_ends(new_program):
                # after one attempt at completing program, give up
                print("WARNING: unable to complete program:")
                print(textwrap.indent(program, "  "))

                return program
            program = new_program

        # parse the program
        try:
            p = Program.from_str(program)
        except parsimonious.ParseError as e:
            print("WARNING: error parsing program:")
            print(textwrap.indent(program, "  "))
            print(str(e))

            return program

        previous_input = p.input

        stack_trace = []

        # p gets updated as we run tools, so we have to iterate over the commands manually.
        i = 0
        while i < len(p.commands):
            command = p.commands[i]

            if command.name == "[EOQ]":
                break

            # get the tool function
            tool_func = self.get_builtin(command.name)

            if tool_func is None:
                print(f"tool '{command.name}' not found")
                previous_input = command.output
                i += 1
                continue

            tool_output, tool_details = tool_func(command.input, previous_input)

            if tool_output:
                # For search, concatenate the GPT-3 output with retrieval output. For everything
                # else, replace.
                if command.name == "[search]":
                    command.output += " " + tool_output
                else:
                    command.output = tool_output

            if self.rerun:
                # run model again with modified command output
                new_prefix, new_output = self.rerun_program(
                    prefix, p.commands[: i + 1], command.output
                )

                # replace later commands (i+1 though N), then have the model re-complete the rest of
                # the program
                program = trim_demonstrations(new_prefix + new_output)
                program = self.complete_program(prefix, program)

                try:
                    p = Program.from_str(program)
                except parsimonious.ParseError as e:
                    print("WARNING: error parsing program:")
                    print(textwrap.indent(program, "  "))
                    print(str(e))

                    # If the rerun fails to generate a legitimate program, its unsafe to assume that
                    # it could replace the rest of the original program. The best course of action
                    # is to exit with the best new program.
                    break

                stack_trace.append(
                    StacktraceItem(command, tool_func, tool_output, tool_details, program, p)
                )
            else:
                new_program = prefix + "\n".join(
                    c.to_program_chunk(j) for j, c in enumerate(p.commands)
                )

                # The parsed program does not change since the future commands are not updated.
                # However, the final answer could change due to the new tool output.
                continuation = self.rerun_answer(new_program)
                new_program += continuation
                new_program = trim_demonstrations(new_program)
                stack_trace.append(
                    StacktraceItem(command, tool_func, tool_output, tool_details, new_program, p)
                )

                # TODO: why do we not update `program` here?

            previous_input = command.output
            i += 1

        self.execution_details.append(stack_trace)

        return program
