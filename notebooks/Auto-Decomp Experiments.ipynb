{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a803c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:56:21.322939: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-15 15:56:33.736852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-15 15:56:33.736897: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "with open(os.path.expanduser('~/.openai_api_key'), 'r') as file:\n",
    "    openai.api_key = file.read().replace('\\n', '')\n",
    "\n",
    "import adatest\n",
    "import re\n",
    "import json\n",
    "import jsonlines\n",
    "import seqio\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = \"/etc/ssl/certs/ca-bundle.crt\"\n",
    "# from bigbench.bbseqio import tasks\n",
    "vocabulary=seqio.SentencePieceVocabulary(\"/gscratch/zlab/bparan/projects/cascades/models/t5-spiece.model\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import List\n",
    "import tqdm\n",
    "\n",
    "with open(os.path.expanduser('~/.openai_api_key'), 'r') as file:\n",
    "    openai.api_key = file.read().replace('\\n', '')\n",
    "print(openai.api_key)\n",
    "cache_dir = '/gscratch/zlab/bparan/projects/cascades/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862d9d6",
   "metadata": {},
   "source": [
    "### GPT-3 Model for prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65579be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIModel(adatest.Model):\n",
    "    def __init__(self, model=\"text-davinci-002\", quote=\"\\\"\", temperature=0.7, top_p=1, max_length=30, n=1):\n",
    "        self.model = model\n",
    "        self.api_key = openai.api_key\n",
    "        self.quote = quote\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_length = max_length\n",
    "        self.n = n\n",
    "    def __call__(self, strings):\n",
    "        resp = openai.Completion.create(\n",
    "            model=self.model,\n",
    "            prompt=strings,\n",
    "            max_tokens=self.max_length,\n",
    "            temperature=self.temperature,\n",
    "            top_p=self.top_p,\n",
    "            n=self.n,\n",
    "            stop=self.quote,\n",
    "        )\n",
    "        return [x[\"text\"] for x in resp['choices']]\n",
    "\n",
    "gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=200, quote='', n=1)\n",
    "\n",
    "\n",
    "def get_bb_data(task_name, task_sequence_length, zero=False, few=False, explain=False):\n",
    "    seq_length = task_sequence_length\n",
    "    # By default seqio returns 3_shot.\n",
    "    if zero:\n",
    "        task = seqio.get_mixture_or_task(task_name)\n",
    "    elif few:\n",
    "        task = seqio.get_mixture_or_task(task_name.replace('0_shot', '3_shot'))\n",
    "\n",
    "    ds = task.get_dataset(split=\"all\", sequence_length={\"inputs\": seq_length, \"targets\": seq_length})\n",
    "    instances = []\n",
    "    for enum, ex in enumerate(ds):\n",
    "        instances.append({\"guid\": enum, \n",
    "                          \"input\": ex['inputs_pretokenized'].numpy().decode(),\n",
    "                          \"label\": ex[\"targets_pretokenized\"].numpy().decode()})\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a1631",
   "metadata": {},
   "source": [
    "### Prompt to propose an instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7717d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_decomposition(decomp_prompt, io_pairs, n=20):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=n)\n",
    "    prompt = '''%s. Here are examples of input-output pairs for the task I'm trying to break down.\n",
    "----\n",
    "%s\n",
    "----\n",
    "Steps:\n",
    "1.'''%(decomp_prompt, io_pairs)\n",
    "    return gpt3(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf5052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_instruction(instruct_prompt, io_pairs, n=20):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=n)\n",
    "    prompt = '''%s. Here are examples of input-output pairs for this task.\n",
    "----\n",
    "%s\n",
    "----\n",
    "I can do this task by'''%(instruct_prompt, io_pairs)\n",
    "    return gpt3(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca45444",
   "metadata": {},
   "source": [
    "### Automatic Decomposition Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af46cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941160e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(inputs, labels, n=100):\n",
    "    idxs = np.random.choice(len(inputs), n, replace=False)\n",
    "    labs = np.array([labels[i] for i in idxs])\n",
    "    subset = [inputs[i] for i in idxs]\n",
    "    return labs, subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1225c",
   "metadata": {},
   "source": [
    "# Tasks \n",
    "\n",
    "For each tasks, we compute:\n",
    "* Best current performance using BigBench instruction\n",
    "* Best human decomposition performance over N runs: Known decomps or ones that we come up with. A further variant of this is (a) Decompositing into individual GPT-3 calls with few-shot prompting (decompositional prompting) and (b) Making and integrating external affordance calls when needed.\n",
    "* Automatic instruction generation (APE): Reporting on top-K instructions. APE reports average over top-10 for 200 instructions. They also have an efficient score estimation technique whereby promising candidates (evaluated based on a small subset) are given more compute resource. \n",
    "* Automatic decomposition generation, followed by zero-shot application to downstream task. Reporting average performance over top-k decompositions\n",
    "* Automtic decomposition: Instruction refinement and decomposition ensembling\n",
    "* Potential affordance calls and decompsoitions with those calls. \n",
    "* Human-LLM collaborative decompositions\n",
    "\n",
    "Things to keep track of:\n",
    "* Evaluation metric computation\n",
    "* Generated sequence length \n",
    "* Fitting in as many decompositions into the promtp as possible\n",
    "\n",
    "Things to think about:\n",
    "* Affordance calls and their integration into the decomposition\n",
    "* Human GPT-3 Collaboration for decompositions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f1095",
   "metadata": {},
   "source": [
    "#### Anachronisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c16e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/mmfs1/home/bparan/.cache/huggingface/datasets/bigbench/anachronisms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe7608bbb6746b6bd4291be7e00f002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data\n",
    "d = datasets.load_dataset('bigbench', 'anachronisms')\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = np.array([int(x[0] == 'Yes') for x in d['train']['targets'] + d['validation']['targets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "666ef707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Performance:\n",
      "Mean 0.7826086956521738\n",
      "Std. Dev 0.7826086956521738\n"
     ]
    }
   ],
   "source": [
    "# Human Decomp \n",
    "def anachronism(x):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=200, quote='---', n=1)\n",
    "    prompt = '''Given a sentence and the time periods of each entity in it, tell me if it could have happened or not.\n",
    "Sentence: I wrote about shakespeare\n",
    "Entities and dates:\n",
    "I -> 21st century\n",
    "Shakespeare -> 16th century\n",
    "Could the sentence be true based on the dates alone: Yes\n",
    "----\n",
    "Sentence: Shakespeare wrote about me\n",
    "\n",
    "Entities and dates:\n",
    "Shakespeare -> 16th century\n",
    "I -> 21st century\n",
    "\n",
    "Could the sentence be true based on the dates alone: No\n",
    "----\n",
    "Sentence: %s''' % x\n",
    "    return gpt3(prompt)\n",
    "\n",
    "perf_array = []\n",
    "runs = 2\n",
    "for run in range(runs): \n",
    "    answers = []\n",
    "    for x in inputs:\n",
    "        answers.append(anachronism(x))\n",
    "    preds = np.array([int(x[0].endswith('No')) for x in answers])\n",
    "    perf_array.append((preds == labels).mean())\n",
    "print(\"Human Performance:\")\n",
    "print(\"Mean\", np.mean(perf_array))\n",
    "print(\"Std. Dev\", np.mean(perf_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c685df6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction 0\n",
      "0.63\n",
      "Instruction 1\n",
      "0.61\n",
      "Instruction 2\n",
      "0.5\n",
      "Instruction 3\n",
      "0.58\n",
      "Instruction 4\n",
      "0.63\n",
      "Instruction 5\n",
      "0.62\n",
      "Instruction 6\n",
      "0.62\n",
      "Instruction 7\n",
      "0.58\n",
      "Instruction 8\n",
      "0.66\n",
      "Instruction 9\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "# Automatic instruction runs.\n",
    "\n",
    "instruct_prompt = 'I want to figure out whether a sentence contains anachronisms or not. An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time.'\n",
    "io_pairs = \"\"\"Input: George Washington fought in the American Civil War.\n",
    "Output: No\n",
    "Input: The Mongolian horse rider used his bow to hunt the velociraptor.\n",
    "Output: Yes\n",
    "Input: Beats from the MPC3000 helped inspire many original blues artists.\n",
    "Output: No\n",
    "Input: Attila the Hun acted in the live-action remake of Mulan.\n",
    "Output: Yes\n",
    "Input: Kurt Cobain starred in the 1990 television show \"Twin Peaks\".\n",
    "Output: Yes\"\"\"\n",
    "\n",
    "instructions = propose_instruction(instruct_prompt, io_pairs, 50)\n",
    "\n",
    "def get_anachronism_ape_fn(instruction, batch_size=10):\n",
    "#     decomposition = '1.'+ decomposition\n",
    "#     last_n = int(re.findall(r'(\\d+)\\.', decomposition)[-1])\n",
    "#     decomposition += '\\n%s. Output YES if there is an anachronism, and NO otherwise' % (last_n + 1)\n",
    "    instruction = instruction.strip()\n",
    "    def decomposition_ape_fn(sentences):\n",
    "        gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=1)\n",
    "        out = []\n",
    "        for chunk in chunks(sentences, batch_size):\n",
    "            prompts = ['''An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time. Figure out whether a sentence contains anachronisms or not, using this instruction.\n",
    "Instruction:\n",
    "%s\n",
    "----\n",
    "Sentence: %s\n",
    "Is this an Anachronism? Output YES if there is an anachronism, and NO otherwise.''' % (instruction, x) for x in chunk]\n",
    "            out.extend(gpt3(prompts))\n",
    "        return out\n",
    "    return decomposition_ape_fn\n",
    "\n",
    "labs, subset = get_subset(inputs, labels, n=100)\n",
    "all_preds = []\n",
    "pps = []\n",
    "accs = []\n",
    "for z, instruction in enumerate(instructions):\n",
    "    print('Instruction', z)\n",
    "    fn = get_anachronism_ape_fn(instruction, batch_size=20)\n",
    "    this_preds = fn(subset)\n",
    "    pp = np.array([1 if 'yes' in x.lower() else 0 for x in this_preds])\n",
    "    all_preds.append(this_preds)\n",
    "    pps.append(pp)\n",
    "    accs.append((pp==labs).mean())\n",
    "    print((pp==labs).mean())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438263eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2efca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition 0\n",
      "0.55\n",
      "Decomposition 1\n",
      "0.66\n",
      "Decomposition 2\n",
      "0.59\n",
      "Decomposition 3\n",
      "0.57\n",
      "Decomposition 4\n",
      "0.54\n",
      "Decomposition 5\n",
      "0.64\n",
      "Decomposition 6\n",
      "0.6\n",
      "Decomposition 7\n",
      "0.59\n",
      "Decomposition 8\n",
      "0.66\n",
      "Decomposition 9\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "# Automatic decomposition runs\n",
    "\n",
    "decomp_prompt = 'I want to break down the task of figuring out whether a sentence contains anachronisms or not, into individual steps. An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time.'\n",
    "decompositions = propose_decomposition(decomp_prompt, io_pairs, 10)\n",
    "\n",
    "def get_anachronism_fn(decomposition, batch_size=10):\n",
    "    decomposition = '1.'+ decomposition\n",
    "    last_n = int(re.findall(r'(\\d+)\\.', decomposition)[-1])\n",
    "#     decomposition += '\\n%s. Output YES if there is an anachronism, and NO otherwise' % (last_n + 1)\n",
    "    def decomposition_fn(sentences):\n",
    "        gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=1)\n",
    "        out = []\n",
    "        for chunk in chunks(sentences, batch_size):\n",
    "            prompts = ['''Figure out whether a sentence contains anachronisms or not, using the following steps\n",
    "Steps:\n",
    "%s\n",
    "----\n",
    "Sentence: %s\n",
    "Is this an Anachronism? Show me how you arrived at this answer step-wise. Output YES if there is an anachronism, and NO otherwise.''' % (decomposition, x) for x in chunk]\n",
    "            out.extend(gpt3(prompts))\n",
    "        return out\n",
    "    return decomposition_fn\n",
    "\n",
    "\n",
    "labs, subset = get_subset(inputs, labels, n=100)\n",
    "preds = []\n",
    "pps = []\n",
    "accs = []\n",
    "all_preds = []\n",
    "for z, decomposition in enumerate(decompositions):\n",
    "    print('Decomposition', z)\n",
    "    fn = get_anachronism_fn(decomposition, batch_size=20)\n",
    "    this_preds = fn(subset)\n",
    "#     pp = np.array([1 if 'contains an anachronism' in x.lower() else 0 for x in this_preds])\n",
    "    pp = np.array([1 if 'yes' in x.lower() else 0 for x in this_preds])\n",
    "    preds.append(this_preds)\n",
    "    pps.append(pp)\n",
    "    accs.append((pp==labs).mean())\n",
    "    print((pp==labs).mean())\n",
    "    all_preds.append(this_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e895b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34858992",
   "metadata": {},
   "source": [
    "#### Dataset from decomposed prompting (K'th letter concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec13d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Take the letters at position 3 of the words in \"Musa Haiying Schmidt Robinson Afzal\" and concatenate them using a space.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/allenai/DecomP/main/datasets/letter_cat/n5_eg100_pos2_space.json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "inputs = [d['question'] for d in data['1']['qa_pairs']]\n",
    "labels = [d['answer']['spans'][0] for d in data['1']['qa_pairs']]\n",
    "len(data['1']['qa_pairs'])\n",
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b7e26ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s i h b z'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f54c8e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual decomposition\n",
    "out = []\n",
    "batch_size = 10\n",
    "for chunk in tqdm.tqdm(chunks(inputs, batch_size)):\n",
    "    prompts = [x for x in chunk]\n",
    "#     print(prompts)\n",
    "    out.extend(gpt3(prompts))\n",
    "pp = np.array([1 if p.strip().lower() == l else 0 for p, l in zip(out, labels)])\n",
    "pp.sum()/len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5235b50",
   "metadata": {},
   "source": [
    "#### Dataset from decomposed prompting (List reversal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "820509d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/allenai/DecomP/main/datasets/reverse/test_10_normal_words.json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "inputs = [d['question'] for d in data['alg_qa']['qa_pairs']]\n",
    "labels = [d['answer']['spans'][0] for d in data['alg_qa']['qa_pairs']]\n",
    "# len(data['1']['qa_pairs'])\n",
    "len(data['alg_qa']['qa_pairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "09e0afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:07,  1.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual decomposition\n",
    "out = []\n",
    "batch_size = 10\n",
    "for chunk in tqdm.tqdm(chunks(inputs, batch_size)):\n",
    "    prompts = [x for x in chunk]\n",
    "#     print(prompts)\n",
    "    out.extend(gpt3(prompts))\n",
    "pp = np.array([1 if p.strip().lower() == l else 0 for p, l in zip(out, labels)])\n",
    "pp.sum()/len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24ff32",
   "metadata": {},
   "source": [
    "#### Tasks in Self-prompt (Ofir's paper) \n",
    "Musique and 2wikimultihop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6596b876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-a426bd25b30faa3b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /mmfs1/home/bparan/.cache/huggingface/datasets/json/default-a426bd25b30faa3b/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a69890c01842649de4b290ea7ea413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9cca8ae9704f5f95dd903dfd148506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /mmfs1/home/bparan/.cache/huggingface/datasets/json/default-a426bd25b30faa3b/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba35e393875b4e7d8eaa4dda812809e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Musique\n",
    "data_files = {split:os.path.join(cache_dir, 'musique', 'data', 'musique_full_v1.0_%s.jsonl'%split) for split in ['train', 'dev']}\n",
    "d = datasets.load_dataset('json', data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-8da56daef1cdd353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /mmfs1/home/bparan/.cache/huggingface/datasets/json/default-8da56daef1cdd353/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7d9ed1adc74809857324e91cab467a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35e6a21b430439a96a4b24e211e85f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ab5378eee44c529495b0955bcaee42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2wikimultihop\n",
    "data_files = {split:os.path.join(cache_dir, '2wikimultihop', 'data', '%s.json'%split) for split in ['train', 'dev']}\n",
    "d = datasets.load_dataset('json', data_files=data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609e970",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Known Unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "481840a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/known_unknowns/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52907300d76248069aac4fb1f9eb2339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "d = datasets.load_dataset('bigbench', 'known_unknowns', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e7309",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Strategy QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b5222b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/strategyqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c4409edab54fb885eea549518047f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "d = datasets.load_dataset('bigbench', 'strategyqa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ad6db",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Hindu Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bfaa3e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/hindu_knowledge/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c19a2ea665649b69c59961dfa5f3c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'hindu_knowledge', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95918f",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Movie Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ce0b40e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/movie_dialog_same_or_different (download: Unknown size, generated: 54.67 MiB, post-processed: Unknown size, total: 54.67 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/movie_dialog_same_or_different/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/movie_dialog_same_or_different/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d2bd46c0594072b36d01641a96b82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'movie_dialog_same_or_different', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96185da6",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Code Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e8b086f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/code_line_description (download: Unknown size, generated: 65.91 KiB, post-processed: Unknown size, total: 65.91 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/code_line_description/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/code_line_description/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 12:55:43.847088: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02a8aac77f94358b12ad4f1d55e382a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'code_line_description', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1700ed",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - conceptual_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0dd73e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/conceptual_combinations/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8129b4b31c26403298011f3ff7125cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'conceptual_combinations', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3886ba87",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - language_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2eb4fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/language_identification (download: Unknown size, generated: 14.10 MiB, post-processed: Unknown size, total: 14.10 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/language_identification/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/language_identification/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930f17d5643143e4a7b5c86c2cb34a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'language_identification', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f431c8",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - vitaminc_fact_verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "63360ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/vitaminc_fact_verification/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c52b29c5a7456d8ecf79b03ee0180c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'vitaminc_fact_verification', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a1252",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - formal_fallacies_syllogisms_negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fc6256df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/formal_fallacies_syllogisms_negation (download: Unknown size, generated: 15.87 MiB, post-processed: Unknown size, total: 15.87 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/formal_fallacies_syllogisms_negation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/14200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/formal_fallacies_syllogisms_negation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a00e4057ef4968b66e0cc6f31436a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'formal_fallacies_syllogisms_negation', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c759da",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - misconceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9fd1a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/misconceptions (download: Unknown size, generated: 89.72 KiB, post-processed: Unknown size, total: 89.72 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/misconceptions/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/43 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/misconceptions/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc80bd94e396417b9bccc866a91c8747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'misconceptions', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f0d1ee26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\\n\\n\\nPassage: Garfield-COLON- A Tail of Two Kitties: The film received negative reviews from critics and it earned $ 141.7 million on a $ 60 million budget.\\nClaim: Garfield : A Tail of Two Kitties received bleak reviews .\\nTrue, False, or Neither?'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53cd7b2",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - logical_deduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "dcf8e656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/winowhy (download: Unknown size, generated: 1.91 MiB, post-processed: Unknown size, total: 1.91 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/winowhy/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: winowhy has 3 duplicate examples out of 2865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/572 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/winowhy/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a2ad57c94c4f94a238fe5eccb8da46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'logical_deduction', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa861e77",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - winowhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f006e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/winowhy/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3094d11475545b099d4149caadd5157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'winowhy', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c1bd6",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - novel_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0992f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/novel_concepts/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac37fea13074cf1867ad1b073983002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'novel_concepts', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb352fb",
   "metadata": {},
   "source": [
    "#### Tasks in Auto-Cot - MAWPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9672b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration omarxadel--MaWPS-ar-e0d2ee7eb9fa6fdb\n",
      "WARNING:datasets.builder:Found cached dataset csv (/gscratch/zlab/bparan/projects/cascades/data/omarxadel___csv/omarxadel--MaWPS-ar-e0d2ee7eb9fa6fdb/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdea24f74c842a883de210717448f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('omarxadel/MaWPS-ar', 'test', cache_dir=cache_dir)\n",
    "inputs = [list(d.values())[0] for d in data['validation']]\n",
    "labels = []\n",
    "for d in data['validation']:\n",
    "    try:\n",
    "        ans = eval(list(d.values())[1].split(\"=\")[-1].strip())\n",
    "        if isinstance(ans, int):\n",
    "            labels.append(ans)\n",
    "        elif (ans).is_integer():\n",
    "            labels.append(int(ans))\n",
    "        else:\n",
    "            labels.append(float(\"%.2f\" % ans))\n",
    "        \n",
    "    except:\n",
    "        ans = eval(list(d.values())[1].split(\"=\")[0].strip())\n",
    "        if isinstance(ans, int):\n",
    "            labels.append(ans)\n",
    "        elif (ans).is_integer():\n",
    "            labels.append(int(ans))\n",
    "        else:\n",
    "            labels.append(float(\"%.2f\" % ans))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03939ba",
   "metadata": {},
   "source": [
    "#### Tasks in Auto-CoT (GSM8K) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "11f139ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset gsm8k (/gscratch/zlab/bparan/projects/cascades/data/gsm8k/main/1.1.0/37bfb08b1d4fcbb01f06b03d9e1ef5f1fcbd4d3af3d08842c50d7305091285ba)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4a5d9f0d184caca424c0d917152c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('gsm8k', 'main', cache_dir=cache_dir)['test']\n",
    "inputs = [d['question'] for d in data]\n",
    "labels = [d['answer'].split('#### ')[-1] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1155251",
   "metadata": {},
   "source": [
    "#### Tasks on Auto-CoT (AQUA-RAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "64a68681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset aqua_rat (/gscratch/zlab/bparan/projects/cascades/data/aqua_rat/raw/0.0.0/fc47b9f437236ab96fc1fcb61096aa193819aedd76437893e2390ab0740a3381)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e6777075404d81981fe5fedca07100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('aqua_rat', 'raw', cache_dir=cache_dir)['validation']\n",
    "inputs = [d['question'] + \" \".join(d['options']) for d in data]\n",
    "labels = [d['correct'] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c2fb3",
   "metadata": {},
   "source": [
    "#### Tasks on Auto-CoT (Commonsense QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "709b807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset commonsense_qa (/gscratch/zlab/bparan/projects/cascades/data/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04b0e80a4ab497b899bcde76407b7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('commonsense_qa', cache_dir=cache_dir)['validation']\n",
    "inputs = [d['question']+ \" \" + \" \".join([k + \") \" + v for k, v in zip(d['choices']['label'], d['choices']['text'])]) for d in data]\n",
    "labels = [d['answerKey'] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d6ee6",
   "metadata": {},
   "source": [
    "#### AMA Tasks (From Super-Glue they include boolQ, cb, copa, multirc, record, rte, wsc, WiC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "accca089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset super_glue (/gscratch/zlab/bparan/projects/cascades/data/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612959773ee240b6aaec658ef258da4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BoolQ\n",
    "data = datasets.load_dataset('super_glue', 'boolq', cache_dir=cache_dir)['validation']\n",
    "inputs = [d['passage']+ \" \" + d['question'][0].title() + d['question'][1:]  + \"?\" for d in data]\n",
    "label_dict = {0:'False', 1:'True'}\n",
    "labels = [label_dict[d['label']] for d in data]\n",
    "# Similar transformations to be made for other Superglue tasks: cb, copa, multirc, record, rte, wsc, wic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fc8249",
   "metadata": {},
   "source": [
    "#### AMA Tasks (From Adversarial NLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4e7cd285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset anli (/gscratch/zlab/bparan/projects/cascades/data/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70388adbb624042b83e317439e0d841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Can also look at dev_r2, dev_r2\n",
    "data = datasets.load_dataset('anli', cache_dir=cache_dir)['dev_r3']\n",
    "inputs = [\"Sentence1: \" + d['premise'] + \"\\nSentence2: \" +d['hypothesis'] for d in data]\n",
    "label_dict = {0:\"entailment\", 1:'neutral', 2:'contradiction'}\n",
    "labels = [label_dict[d['label']] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad5715",
   "metadata": {},
   "source": [
    "#### Flipped Learning tasks Storycloze, PIQA, HellaSwag, ARC challenge and openbookQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5368aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-fe6cd1e9646dcb63\n",
      "WARNING:datasets.builder:Found cached dataset story_cloze (/mmfs1/home/bparan/.cache/huggingface/datasets/story_cloze/default-fe6cd1e9646dcb63/0.0.0/45cead0538c3deb72d731a7990e60835c2c9c5d5d5b1e95a7dd47ccf593671e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27aec5bc2eb472ba96e0973474b3b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1571"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# story_cloze\n",
    "validation_path = os.path.join(cache_dir, 'story_cloze') #, 'cloze_test_val__winter2018-cloze_test_ALL_val - 1 - 1.csv')\n",
    "data = datasets.load_dataset('story_cloze', data_dir=validation_path)\n",
    "len(data['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ec7cbefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset piqa (/gscratch/zlab/bparan/projects/cascades/data/piqa/plain_text/1.1.0/6c611c1a9bf220943c4174e117d3b660859665baf1d43156230116185312d011)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3551f8c9fe1548ffb7a27ef065c95842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'goal': \"How do I ready a guinea pig cage for it's new occupants?\",\n",
       " 'sol1': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped paper strips, you will also need to supply it with a water bottle and a food dish.',\n",
       " 'sol2': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped jeans material, you will also need to supply it with a water bottle and a food dish.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_dataset('piqa', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6907a811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset hellaswag (/gscratch/zlab/bparan/projects/cascades/data/hellaswag/default/0.1.0/c37cd37196278995f42bc32f532730ae9b0d5f0f4a2d3b97735c17ff3ad67169)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be88dd9dbb4b49e2b2b1064d3c7dd61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ind': 24,\n",
       " 'activity_label': 'Roof shingle removal',\n",
       " 'ctx_a': 'A man is sitting on a roof.',\n",
       " 'ctx_b': 'he',\n",
       " 'ctx': 'A man is sitting on a roof. he',\n",
       " 'endings': ['is using wrap to wrap a pair of skis.',\n",
       "  'is ripping level tiles off.',\n",
       "  \"is holding a rubik's cube.\",\n",
       "  'starts pulling up roofing on a roof.'],\n",
       " 'source_id': 'activitynet~v_-JhWjGDPHMY',\n",
       " 'split': 'val',\n",
       " 'split_type': 'indomain',\n",
       " 'label': '3'}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_dataset('hellaswag', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8def24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset ai2_arc (/gscratch/zlab/bparan/projects/cascades/data/ai2_arc/ARC-Challenge/1.0.0/1569c2591ea2683779581d9fb467203d9aa95543bb9b75dcfde5da92529fd7f6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92cc5db9516432fa3bc296cf71dd790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_412337',\n",
       " 'question': 'During an investigation, heat transferred from a liquid to the environment. Which pair of explanations can best account for this result?',\n",
       " 'choices': {'text': ['The temperature of the liquid increased, or the liquid became a gas.',\n",
       "   'The temperature of the liquid increased, or the liquid became a solid.',\n",
       "   'The temperature of the liquid decreased, or the liquid became a gas.',\n",
       "   'The temperature of the liquid decreased, or the liquid became a solid.'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'D'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is also the ARC-easy split\n",
    "data = datasets.load_dataset('ai2_arc', 'ARC-Challenge', cache_dir=cache_dir)['validation']\n",
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "87329332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset openbookqa (/gscratch/zlab/bparan/projects/cascades/data/openbookqa/main/1.0.1/f338ccacfbc86fb8c2de3aa1c06d2ce686933de3bca284dba97d32592c52b33f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4d5d19360f4086a4958154069fcb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '8-376',\n",
       " 'question_stem': 'Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as',\n",
       " 'choices': {'text': ['Deep sea animals',\n",
       "   'fish',\n",
       "   'Long Sea Fish',\n",
       "   'Far Sea Animals'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'A'}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenbookQa\n",
    "data = datasets.load_dataset('openbookqa', 'main', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f35b9a",
   "metadata": {},
   "source": [
    "#### Other tasks from AMA (Classification) : Agnews, DBPedia, Amazon movie reivew and SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7f80cbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset ag_news (/gscratch/zlab/bparan/projects/cascades/data/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0758b6a13674b6b9deaf0514cd78d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## For others use the strings : dbpedia_14, sst2\n",
    "data = datasets.load_dataset('ag_news', cache_dir=cache_dir)['test']\n",
    "inputs = [d['text'] for d in data]\n",
    "label_dict = {0:'World', 1:'Sports', 2:'Business', 3: 'Sci/Tech'}\n",
    "labels = [label_dict[d['label']] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a0cae",
   "metadata": {},
   "source": [
    "#### Tasks from reframing natural language instructions\n",
    "\n",
    "MC-Taco (question generation), QASC (question generation), Quoref, Winogrande, CosmosQA, MultiRC, MC-TACO (Incorrect answer generation for duration and transcience questions), QASC (overlapping words), Essential terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "74424eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download natural instructions\n",
    "\n",
    "def transform_example(example):\n",
    "    # Very simple transformation of the example\n",
    "    return example[\"input\"] + \"\\n\" + example[\"output\"]\n",
    "\n",
    "NQ_REWRITE_TASKS = ['task003_mctaco_question_generation_event_duration.json', \n",
    "           'task040_qasc_question_generation.json',\n",
    "           'task002_quoref_answer_generation.json',\n",
    "           'task033_winogrande_answer_generation.json',\n",
    "           'task024_cosmosqa_answer_generation.json',\n",
    "           'task056_multirc_classify_correct_answer.json',\n",
    "           'task005_mctaco_wrong_answer_generation_event_duration.json', \n",
    "           'task008_mctaco_wrong_answer_generation_transient_stationary.json',\n",
    "           'task039_qasc_find_overlapping_words.json',\n",
    "           'task044_essential_terms_identifying_essential_words.json']\n",
    "for task_name in NQ_REWRITE_TASKS:\n",
    "    nq_path = \"/mmfs1/gscratch/zlab/bparan/projects/cascades/src/natural-instructions/tasks\"\n",
    "    task_path = os.path.join(nq_path, task_name)\n",
    "    task_data = json.loads(open(task_path).read())\n",
    "    instances = []\n",
    "    for instance in task_data[\"Instances\"]:\n",
    "        instances.append({\"guid\": instance['id'], \"input\": instance[\"input\"], \"label\": instance[\"output\"][0]})\n",
    "    instruction = task_data[\"Definition\"]\n",
    "    examples = \"\"\n",
    "    for ex in task_data[\"Positive Examples\"]:\n",
    "        examples += transform_example(ex)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a0ad4",
   "metadata": {},
   "source": [
    "#### Additional promising datasets from BigBench\n",
    "\n",
    "* Word Sorting\n",
    "* Word Unscrambling\n",
    "* Which Wikipedia Edit\n",
    "* Unnatural incontext learning\n",
    "* Unit Interpretation\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99d6134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/word_sorting (download: Unknown size, generated: 959.64 KiB, post-processed: Unknown size, total: 959.64 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/word_sorting/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/word_sorting/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16adfc0207714c8582c435bed8c2445c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'word_sorting', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0162585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/word_unscrambling/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c4141876d94939b7738d2850e77fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'word_unscrambling', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f3fe92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/which_wiki_edit (download: Unknown size, generated: 12.08 MiB, post-processed: Unknown size, total: 12.08 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/which_wiki_edit/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/571 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/which_wiki_edit/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5714efc4fe146b295f7e9665c350d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'which_wiki_edit', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9208e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/unnatural_in_context_learning/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f8a03634984b10a9c4375f5be5dacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'unnatural_in_context_learning', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7acf88ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/unit_interpretation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'unit_interpretation', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5da9044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/understanding_fables (download: Unknown size, generated: 445.17 KiB, post-processed: Unknown size, total: 445.17 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/understanding_fables/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/37 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/understanding_fables/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'understanding_fables', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71358ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/tracking_shuffled_objects/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172a65b1213747579a998872a1108ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'tracking_shuffled_objects', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd4f9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/temporal_sequences (download: Unknown size, generated: 1.31 MiB, post-processed: Unknown size, total: 1.31 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/temporal_sequences/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/temporal_sequences/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'temporal_sequences', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1fdb314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/symbol_interpretation (download: Unknown size, generated: 2.19 MiB, post-processed: Unknown size, total: 2.19 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/symbol_interpretation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/795 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/symbol_interpretation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 09:34:18.109367: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-10-13 09:34:18.131926: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da52de51349f4c0bba292d0359fbb4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'symbol_interpretation', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d2a38c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/sufficient_information/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec7a8008c6d4aec94fa1fc7e9f9b69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'sufficient_information', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad7eefb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/sports_understanding (download: Unknown size, generated: 443.48 KiB, post-processed: Unknown size, total: 443.48 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/sports_understanding/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/986 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: sports_understanding has 14 duplicate examples out of 1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/197 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/sports_understanding/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'sports_understanding', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58ec466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/snarks (download: Unknown size, generated: 89.50 KiB, post-processed: Unknown size, total: 89.50 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/snarks/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/145 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/snarks/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'snarks', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0c306be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/simple_text_editing (download: Unknown size, generated: 54.52 KiB, post-processed: Unknown size, total: 54.52 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/simple_text_editing/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/simple_text_editing/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 09:50:32.037137: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'simple_text_editing', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7424855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/sentence_ambiguity (download: Unknown size, generated: 16.07 KiB, post-processed: Unknown size, total: 16.07 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/sentence_ambiguity/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 09:54:48.161775: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/sentence_ambiguity/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 09:54:48.245917: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'sentence_ambiguity', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "866003ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/salient_translation_error_detection (download: Unknown size, generated: 2.18 MiB, post-processed: Unknown size, total: 2.18 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/salient_translation_error_detection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/salient_translation_error_detection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'salient_translation_error_detection', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4fdf315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/riddle_sense (download: Unknown size, generated: 30.43 KiB, post-processed: Unknown size, total: 30.43 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/riddle_sense/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/49 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 10:15:59.806252: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/riddle_sense/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 10:15:59.889900: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'riddle_sense', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "992e2dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/repeat_copy_logic (download: Unknown size, generated: 13.13 KiB, post-processed: Unknown size, total: 13.13 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/repeat_copy_logic/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 10:18:25.874866: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/repeat_copy_logic/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 10:18:25.961445: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'repeat_copy_logic', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08f7f45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/reasoning_about_colored_objects (download: Unknown size, generated: 1.74 MiB, post-processed: Unknown size, total: 1.74 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/reasoning_about_colored_objects/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/reasoning_about_colored_objects/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'reasoning_about_colored_objects', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2fbcb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/real_or_fake_text (download: Unknown size, generated: 102.39 MiB, post-processed: Unknown size, total: 102.39 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/real_or_fake_text/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/15088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/real_or_fake_text/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'real_or_fake_text', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e4480f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/question_selection (download: Unknown size, generated: 4.75 MiB, post-processed: Unknown size, total: 4.75 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/question_selection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1582 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: question_selection has 8 duplicate examples out of 1590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1266 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/316 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/question_selection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'question_selection', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cb31a408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/presuppositions_as_nli (download: Unknown size, generated: 982.28 KiB, post-processed: Unknown size, total: 982.28 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/presuppositions_as_nli/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/presuppositions_as_nli/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'presuppositions_as_nli', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "21035ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/physics_questions (download: Unknown size, generated: 35.98 KiB, post-processed: Unknown size, total: 35.98 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/physics_questions/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/54 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/physics_questions/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:47:28.847296: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa40f8d49b14c5a98cd0535daf02dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'physics_questions', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d84c618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/physical_intuition/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'physical_intuition', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "80850d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/penguins_in_a_table/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89671cbe6e2c4be8805818f95e22aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'penguins_in_a_table', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "211b8771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/operators (download: Unknown size, generated: 63.48 KiB, post-processed: Unknown size, total: 63.48 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/operators/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: operators has 1 duplicate examples out of 211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/168 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/operators/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'operators', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "eade5467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/odd_one_out (download: Unknown size, generated: 27.24 KiB, post-processed: Unknown size, total: 27.24 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/odd_one_out/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/86 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/69 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/odd_one_out/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:57:57.267219: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'odd_one_out', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5ed750a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/object_counting (download: Unknown size, generated: 292.43 KiB, post-processed: Unknown size, total: 292.43 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/object_counting/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/object_counting/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'object_counting', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2a389f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/novel_concepts/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59f51a5717d473ba61f21cdb18b4083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'novel_concepts', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b6425be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/nonsense_words_grammar/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'nonsense_words_grammar', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5376a9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/navigate (download: Unknown size, generated: 441.84 KiB, post-processed: Unknown size, total: 441.84 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/navigate/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/navigate/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'navigate', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0d3d43c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/modified_arithmetic (download: Unknown size, generated: 2.33 MiB, post-processed: Unknown size, total: 2.33 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/modified_arithmetic/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/modified_arithmetic/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'modified_arithmetic', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bcacbfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/minute_mysteries_qa (download: Unknown size, generated: 6.19 MiB, post-processed: Unknown size, total: 6.19 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/minute_mysteries_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/94 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/minute_mysteries_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'minute_mysteries_qa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ee651dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/metaphor_boolean (download: Unknown size, generated: 418.24 KiB, post-processed: Unknown size, total: 418.24 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/metaphor_boolean/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/544 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/136 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/metaphor_boolean/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'metaphor_boolean', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "efdcd266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/logical_sequence (download: Unknown size, generated: 44.50 KiB, post-processed: Unknown size, total: 44.50 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_sequence/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 14:10:53.155483: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 14:10:53.242602: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_sequence/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 14:10:53.324030: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'logical_sequence', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "87b1969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/logical_fallacy_detection (download: Unknown size, generated: 1.38 MiB, post-processed: Unknown size, total: 1.38 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_fallacy_detection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/560 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_fallacy_detection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d5331cb6ce4d5db24803403a6070c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'logical_fallacy_detection', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f272d6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_deduction/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'logical_deduction', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b3135195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/logical_args (download: Unknown size, generated: 85.24 KiB, post-processed: Unknown size, total: 85.24 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_args/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 20:52:20.466628: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 20:52:20.564030: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 20:52:20.662655: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_args/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'logical_args', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6d3b3cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/linguistics_puzzles (download: Unknown size, generated: 3.33 MiB, post-processed: Unknown size, total: 3.33 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/linguistics_puzzles/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/linguistics_puzzles/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'linguistics_puzzles', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "58efa4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/language_games/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ece20a1aa447d8804ddd78eb6008b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'language_games', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c93d7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/intent_recognition (download: Unknown size, generated: 631.06 KiB, post-processed: Unknown size, total: 631.06 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/intent_recognition/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/693 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/555 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/intent_recognition/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'intent_recognition', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7beb5bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/implicit_relations (download: Unknown size, generated: 156.30 KiB, post-processed: Unknown size, total: 156.30 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/implicit_relations/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/85 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/implicit_relations/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'implicit_relations', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d7732513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/implicatures (download: Unknown size, generated: 179.50 KiB, post-processed: Unknown size, total: 179.50 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/implicatures/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/492 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/implicatures/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'implicatures', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "348cf453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/11.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/284k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/identify_odd_metaphor (download: Unknown size, generated: 54.04 KiB, post-processed: Unknown size, total: 54.04 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/identify_odd_metaphor/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 20:43:27.791681: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/identify_odd_metaphor/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 20:43:27.967707: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'identify_odd_metaphor', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "80b49c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/hyperbaton (download: Unknown size, generated: 17.93 MiB, post-processed: Unknown size, total: 17.93 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/hyperbaton/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/hyperbaton/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'hyperbaton', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d9cf628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/formal_fallacies_syllogisms_negation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'formal_fallacies_syllogisms_negation', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3d3181fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/few_shot_nlg (download: Unknown size, generated: 148.44 KiB, post-processed: Unknown size, total: 148.44 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/few_shot_nlg/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/123 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/few_shot_nlg/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'few_shot_nlg', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "69f524e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/evaluating_information_essentiality (download: Unknown size, generated: 151.52 KiB, post-processed: Unknown size, total: 151.52 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/evaluating_information_essentiality/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/evaluating_information_essentiality/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 12:47:46.684679: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'evaluating_information_essentiality', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "22c9f57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/epistemic_reasoning (download: Unknown size, generated: 1.69 MiB, post-processed: Unknown size, total: 1.69 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/epistemic_reasoning/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/epistemic_reasoning/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'epistemic_reasoning', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e88ae07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/empirical_judgments/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d58e1c98e3411d8af1821295812035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'empirical_judgments', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d8924459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/elementary_math_qa (download: Unknown size, generated: 25.69 MiB, post-processed: Unknown size, total: 25.69 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/elementary_math_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/38160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: elementary_math_qa:language_hint_only has 140 duplicate examples out of 7688\n",
      "warning: elementary_math_qa:mathematical_hint_only has 140 duplicate examples out of 7688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/30531 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/7629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/elementary_math_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'elementary_math_qa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "3c73d8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/discourse_marker_prediction (download: Unknown size, generated: 3.99 MiB, post-processed: Unknown size, total: 3.99 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/discourse_marker_prediction/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/857 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/686 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/discourse_marker_prediction/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'discourse_marker_prediction', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6602cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/disambiguation_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'disambiguation_qa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "39ef89de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/date_understanding (download: Unknown size, generated: 186.06 KiB, post-processed: Unknown size, total: 186.06 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/date_understanding/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/date_understanding/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'date_understanding', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "7bb03721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/cs_algorithms (download: Unknown size, generated: 533.76 KiB, post-processed: Unknown size, total: 533.76 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/cs_algorithms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1056 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/cs_algorithms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'cs_algorithms', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8dc74cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/crash_blossom (download: Unknown size, generated: 23.93 KiB, post-processed: Unknown size, total: 23.93 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/crash_blossom/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:45:16.755606: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/crash_blossom/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:45:16.841486: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'crash_blossom', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "39ec858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/contextual_parametric_knowledge_conflicts (download: Unknown size, generated: 27.84 MiB, post-processed: Unknown size, total: 27.84 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/contextual_parametric_knowledge_conflicts/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/17528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14023 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3505 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/contextual_parametric_knowledge_conflicts/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'contextual_parametric_knowledge_conflicts', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "e845741b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/conceptual_combinations/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'conceptual_combinations', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "27056f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/common_morpheme/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'common_morpheme', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "837d7c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/codenames (download: Unknown size, generated: 49.31 KiB, post-processed: Unknown size, total: 49.31 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/codenames/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/85 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/codenames/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:49:50.762256: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'codenames', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "29e888a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/bridging_anaphora_resolution_barqa (download: Unknown size, generated: 3.76 MiB, post-processed: Unknown size, total: 3.76 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'bridging_anaphora_resolution_barqa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "308701b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/bridging_anaphora_resolution_barqa (download: Unknown size, generated: 3.76 MiB, post-processed: Unknown size, total: 3.76 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'analogical_similarity', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "158ae193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/bridging_anaphora_resolution_barqa (download: Unknown size, generated: 3.76 MiB, post-processed: Unknown size, total: 3.76 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'abstract_narrative_understanding', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "eaf87c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/auto_debugging (download: Unknown size, generated: 10.08 KiB, post-processed: Unknown size, total: 10.08 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/auto_debugging/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/34 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/auto_debugging/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:52:31.091462: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3f0bc0b1f54b1e9489ee213f58ab89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'auto_debugging', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "cf4205bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "if x < 5:\n",
      "\tpass\n",
      "```\n",
      "What error does this program surface?\n",
      "[\"NameError: name 'x' is not defined\"]\n",
      "----------\n",
      "\n",
      "```\n",
      "d = {1: 'hello', 2: 'bye', 3: 'good morning'}\n",
      "str_ = ''\n",
      "for i in range(len(d)):\n",
      "\tif i % 2 == 1:\n",
      "\t\tstr_ += d[i]\n",
      "```\n",
      "What is the value of str_ after this program executes?\n",
      "['hellogood morning']\n",
      "----------\n",
      "\n",
      "```\n",
      "class MyClass():\n",
      "\tdef __init__(self, param):\n",
      "\t\tself.param = param\n",
      "x = MyClass(5)\n",
      "y = MyClass(x.param)\n",
      "```\n",
      "What is the value of x.param at the end of this program?\n",
      "['5']\n",
      "----------\n",
      "\n",
      "```\n",
      "def sq(x):\n",
      "\treturn x*x\n",
      "y = sq(5)\n",
      "x = sq(3)\n",
      "```\n",
      "What is the value of x at the end of this program?\n",
      "['9']\n",
      "----------\n",
      "\n",
      "```\n",
      "class MyClass():\n",
      "\tdef __init__(self):\n",
      "\t\tprint(param)\n",
      "x = MyClass(5)\n",
      "```\n",
      "What is the value of x.param at the end of this program?\n",
      "['None']\n",
      "----------\n",
      "\n",
      "```\n",
      "while True\n",
      "\tprint('hello world')\n",
      "```\n",
      "What type of exception does this program produce?\n",
      "['SyntaxError: invalid syntax']\n",
      "----------\n",
      "\n",
      "```\n",
      "sum = 0\n",
      "for i in range(100):\n",
      "\tsum += i\n",
      "```\n",
      "What is the value of sum immediately after the 10th time line 3 is executed?\n",
      "['45']\n",
      "----------\n",
      "\n",
      "```\n",
      "y = list(map(int, ['1', 'hello', '2']))\n",
      "```\n",
      "What error does this program produce?\n",
      "[\"ValueError: invalid literal for int() with base 10: 'hello'\"]\n",
      "----------\n",
      "\n",
      "```\n",
      "sum = 0\n",
      "for i in range(100, 0, -2):\n",
      "\tsum += i\n",
      "```\n",
      "What is the value of sum at the end of this program?\n",
      "['2550']\n",
      "----------\n",
      "\n",
      "```\n",
      "def sq(x):\n",
      "\treturn x*x\n",
      "y = sq(5)\n",
      "x = sq(y)\n",
      "```\n",
      "What is the value of x at the end of this program?\n",
      "['625']\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(inputs[i])\n",
    "    print(labels[i])\n",
    "    print('-'*10 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fb052ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7854"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
