{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a803c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "with open(os.path.expanduser('~/.openai_api_key'), 'r') as file:\n",
    "    openai.api_key = file.read().replace('\\n', '')\n",
    "\n",
    "import adatest\n",
    "import re\n",
    "import json\n",
    "import jsonlines\n",
    "import seqio\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = \"/etc/ssl/certs/ca-bundle.crt\"\n",
    "# from bigbench.bbseqio import tasks\n",
    "vocabulary=seqio.SentencePieceVocabulary(\"/gscratch/zlab/bparan/projects/cascades/models/t5-spiece.model\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import List\n",
    "import tqdm\n",
    "\n",
    "with open(os.path.expanduser('~/.openai_api_key'), 'r') as file:\n",
    "    openai.api_key = file.read().replace('\\n', '')\n",
    "print(openai.api_key)\n",
    "cache_dir = '/gscratch/zlab/bparan/projects/cascades/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862d9d6",
   "metadata": {},
   "source": [
    "### GPT-3 Model for prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65579be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIModel(adatest.Model):\n",
    "    def __init__(self, model=\"text-davinci-002\", quote=\"\\\"\", temperature=0.7, top_p=1, max_length=30, n=1):\n",
    "        self.model = model\n",
    "        self.api_key = openai.api_key\n",
    "        self.quote = quote\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_length = max_length\n",
    "        self.n = n\n",
    "    def __call__(self, strings):\n",
    "        resp = openai.Completion.create(\n",
    "            model=self.model,\n",
    "            prompt=strings,\n",
    "            max_tokens=self.max_length,\n",
    "            temperature=self.temperature,\n",
    "            top_p=self.top_p,\n",
    "            n=self.n,\n",
    "            stop=self.quote,\n",
    "        )\n",
    "        return [x[\"text\"] for x in resp['choices']]\n",
    "\n",
    "gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=200, quote='', n=1)\n",
    "\n",
    "\n",
    "def get_bb_data(task_name, task_sequence_length, zero=False, few=False, explain=False):\n",
    "    seq_length = task_sequence_length\n",
    "    # By default seqio returns 3_shot.\n",
    "    if zero:\n",
    "        task = seqio.get_mixture_or_task(task_name)\n",
    "    elif few:\n",
    "        task = seqio.get_mixture_or_task(task_name.replace('0_shot', '3_shot'))\n",
    "\n",
    "    ds = task.get_dataset(split=\"all\", sequence_length={\"inputs\": seq_length, \"targets\": seq_length})\n",
    "    instances = []\n",
    "    for enum, ex in enumerate(ds):\n",
    "        instances.append({\"guid\": enum, \n",
    "                          \"input\": ex['inputs_pretokenized'].numpy().decode(),\n",
    "                          \"label\": ex[\"targets_pretokenized\"].numpy().decode()})\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a1631",
   "metadata": {},
   "source": [
    "### Prompt to propose an instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7717d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_decomposition(decomp_prompt, io_pairs, n=20):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=n)\n",
    "    prompt = '''%s. Here are examples of input-output pairs for the task I'm trying to break down.\n",
    "----\n",
    "%s\n",
    "----\n",
    "Steps:\n",
    "1.'''%(decomp_prompt, io_pairs)\n",
    "    return gpt3(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf5052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_instruction(instruct_prompt, io_pairs, n=20):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=n)\n",
    "    prompt = '''%s. Here are examples of input-output pairs for this task.\n",
    "----\n",
    "%s\n",
    "----\n",
    "I can do this task by'''%(instruct_prompt, io_pairs)\n",
    "    return gpt3(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca45444",
   "metadata": {},
   "source": [
    "### Automatic Decomposition Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af46cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941160e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(inputs, labels, n=100):\n",
    "    idxs = np.random.choice(len(inputs), n, replace=False)\n",
    "    labs = np.array([labels[i] for i in idxs])\n",
    "    subset = [inputs[i] for i in idxs]\n",
    "    return labs, subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1225c",
   "metadata": {},
   "source": [
    "# Tasks \n",
    "\n",
    "For each tasks, we compute:\n",
    "* Best current performance using BigBench instruction\n",
    "* Best human decomposition performance over N runs: Known decomps or ones that we come up with. A further variant of this is (a) Decompositing into individual GPT-3 calls with few-shot prompting (decompositional prompting) and (b) Making and integrating external affordance calls when needed.\n",
    "* Automatic instruction generation (APE): Reporting on top-K instructions. APE reports average over top-10 for 200 instructions. They also have an efficient score estimation technique whereby promising candidates (evaluated based on a small subset) are given more compute resource. \n",
    "* Automatic decomposition generation, followed by zero-shot application to downstream task. Reporting average performance over top-k decompositions\n",
    "* Automtic decomposition: Instruction refinement and decomposition ensembling\n",
    "* Potential affordance calls and decompsoitions with those calls. \n",
    "* Human-LLM collaborative decompositions\n",
    "\n",
    "Things to keep track of:\n",
    "* Evaluation metric computation\n",
    "* Generated sequence length \n",
    "* Fitting in as many decompositions into the promtp as possible\n",
    "\n",
    "Things to think about:\n",
    "* Affordance calls and their integration into the decomposition\n",
    "* Human GPT-3 Collaboration for decompositions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f1095",
   "metadata": {},
   "source": [
    "#### Anachronisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c16e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/anachronisms (download: Unknown size, generated: 95.60 KiB, post-processed: Unknown size, total: 95.60 KiB) to /mmfs1/home/bparan/.cache/huggingface/datasets/bigbench/anachronisms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 11:36:33.156433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/46 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /mmfs1/home/bparan/.cache/huggingface/datasets/bigbench/anachronisms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8664ddc311814c6589f1d36d2de855c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data\n",
    "d = datasets.load_dataset('bigbench', 'anachronisms')\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = np.array([int(x[0] == 'Yes') for x in d['train']['targets'] + d['validation']['targets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a515b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "666ef707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Performance:\n",
      "Mean 0.7826086956521738\n",
      "Std. Dev 0.7826086956521738\n"
     ]
    }
   ],
   "source": [
    "# Human Decomp \n",
    "def anachronism(x):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=200, quote='---', n=1)\n",
    "    prompt = '''Given a sentence and the time periods of each entity in it, tell me if it could have happened or not.\n",
    "Sentence: I wrote about shakespeare\n",
    "Entities and dates:\n",
    "I -> 21st century\n",
    "Shakespeare -> 16th century\n",
    "Could the sentence be true based on the dates alone: Yes\n",
    "----\n",
    "Sentence: Shakespeare wrote about me\n",
    "\n",
    "Entities and dates:\n",
    "Shakespeare -> 16th century\n",
    "I -> 21st century\n",
    "\n",
    "Could the sentence be true based on the dates alone: No\n",
    "----\n",
    "Sentence: %s''' % x\n",
    "    return gpt3(prompt)\n",
    "\n",
    "perf_array = []\n",
    "runs = 2\n",
    "for run in range(runs): \n",
    "    answers = []\n",
    "    for x in inputs:\n",
    "        answers.append(anachronism(x))\n",
    "    preds = np.array([int(x[0].endswith('No')) for x in answers])\n",
    "    perf_array.append((preds == labels).mean())\n",
    "print(\"Human Performance:\")\n",
    "print(\"Mean\", np.mean(perf_array))\n",
    "print(\"Std. Dev\", np.mean(perf_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c685df6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction 0\n",
      "0.63\n",
      "Instruction 1\n",
      "0.61\n",
      "Instruction 2\n",
      "0.5\n",
      "Instruction 3\n",
      "0.58\n",
      "Instruction 4\n",
      "0.63\n",
      "Instruction 5\n",
      "0.62\n",
      "Instruction 6\n",
      "0.62\n",
      "Instruction 7\n",
      "0.58\n",
      "Instruction 8\n",
      "0.66\n",
      "Instruction 9\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "# Automatic instruction runs.\n",
    "\n",
    "instruct_prompt = 'I want to figure out whether a sentence contains anachronisms or not. An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time.'\n",
    "io_pairs = \"\"\"Input: George Washington fought in the American Civil War.\n",
    "Output: No\n",
    "Input: The Mongolian horse rider used his bow to hunt the velociraptor.\n",
    "Output: Yes\n",
    "Input: Beats from the MPC3000 helped inspire many original blues artists.\n",
    "Output: No\n",
    "Input: Attila the Hun acted in the live-action remake of Mulan.\n",
    "Output: Yes\n",
    "Input: Kurt Cobain starred in the 1990 television show \"Twin Peaks\".\n",
    "Output: Yes\"\"\"\n",
    "\n",
    "instructions = propose_instruction(instruct_prompt, io_pairs, 50)\n",
    "\n",
    "def get_anachronism_ape_fn(instruction, batch_size=10):\n",
    "#     decomposition = '1.'+ decomposition\n",
    "#     last_n = int(re.findall(r'(\\d+)\\.', decomposition)[-1])\n",
    "#     decomposition += '\\n%s. Output YES if there is an anachronism, and NO otherwise' % (last_n + 1)\n",
    "    instruction = instruction.strip()\n",
    "    def decomposition_ape_fn(sentences):\n",
    "        gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=1)\n",
    "        out = []\n",
    "        for chunk in chunks(sentences, batch_size):\n",
    "            prompts = ['''An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time. Figure out whether a sentence contains anachronisms or not, using this instruction.\n",
    "Instruction:\n",
    "%s\n",
    "----\n",
    "Sentence: %s\n",
    "Is this an Anachronism? Output YES if there is an anachronism, and NO otherwise.''' % (instruction, x) for x in chunk]\n",
    "            out.extend(gpt3(prompts))\n",
    "        return out\n",
    "    return decomposition_ape_fn\n",
    "\n",
    "labs, subset = get_subset(inputs, labels, n=100)\n",
    "all_preds = []\n",
    "pps = []\n",
    "accs = []\n",
    "for z, instruction in enumerate(instructions):\n",
    "    print('Instruction', z)\n",
    "    fn = get_anachronism_ape_fn(instruction, batch_size=20)\n",
    "    this_preds = fn(subset)\n",
    "    pp = np.array([1 if 'yes' in x.lower() else 0 for x in this_preds])\n",
    "    all_preds.append(this_preds)\n",
    "    pps.append(pp)\n",
    "    accs.append((pp==labs).mean())\n",
    "    print((pp==labs).mean())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438263eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2efca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition 0\n",
      "0.55\n",
      "Decomposition 1\n",
      "0.66\n",
      "Decomposition 2\n",
      "0.59\n",
      "Decomposition 3\n",
      "0.57\n",
      "Decomposition 4\n",
      "0.54\n",
      "Decomposition 5\n",
      "0.64\n",
      "Decomposition 6\n",
      "0.6\n",
      "Decomposition 7\n",
      "0.59\n",
      "Decomposition 8\n",
      "0.66\n",
      "Decomposition 9\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "# Automatic decomposition runs\n",
    "\n",
    "decomp_prompt = 'I want to break down the task of figuring out whether a sentence contains anachronisms or not, into individual steps. An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time.'\n",
    "decompositions = propose_decomposition(decomp_prompt, io_pairs, 10)\n",
    "\n",
    "def get_anachronism_fn(decomposition, batch_size=10):\n",
    "    decomposition = '1.'+ decomposition\n",
    "    last_n = int(re.findall(r'(\\d+)\\.', decomposition)[-1])\n",
    "#     decomposition += '\\n%s. Output YES if there is an anachronism, and NO otherwise' % (last_n + 1)\n",
    "    def decomposition_fn(sentences):\n",
    "        gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=1)\n",
    "        out = []\n",
    "        for chunk in chunks(sentences, batch_size):\n",
    "            prompts = ['''Figure out whether a sentence contains anachronisms or not, using the following steps\n",
    "Steps:\n",
    "%s\n",
    "----\n",
    "Sentence: %s\n",
    "Is this an Anachronism? Show me how you arrived at this answer step-wise. Output YES if there is an anachronism, and NO otherwise.''' % (decomposition, x) for x in chunk]\n",
    "            out.extend(gpt3(prompts))\n",
    "        return out\n",
    "    return decomposition_fn\n",
    "\n",
    "\n",
    "labs, subset = get_subset(inputs, labels, n=100)\n",
    "preds = []\n",
    "pps = []\n",
    "accs = []\n",
    "all_preds = []\n",
    "for z, decomposition in enumerate(decompositions):\n",
    "    print('Decomposition', z)\n",
    "    fn = get_anachronism_fn(decomposition, batch_size=20)\n",
    "    this_preds = fn(subset)\n",
    "#     pp = np.array([1 if 'contains an anachronism' in x.lower() else 0 for x in this_preds])\n",
    "    pp = np.array([1 if 'yes' in x.lower() else 0 for x in this_preds])\n",
    "    preds.append(this_preds)\n",
    "    pps.append(pp)\n",
    "    accs.append((pp==labs).mean())\n",
    "    print((pp==labs).mean())\n",
    "    all_preds.append(this_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e895b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34858992",
   "metadata": {},
   "source": [
    "#### Dataset from decomposed prompting (K'th letter concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec13d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/allenai/DecomP/main/datasets/letter_cat/n5_eg100_pos2_space.json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "dev_inputs = [d['question'] for d in data['1']['qa_pairs']]\n",
    "dev_labels = [d['answer']['spans'][0] for d in data['1']['qa_pairs']]\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/allenai/DecomP/main/datasets/letter_cat/n4_eg100_pos2_space.json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "train_inputs = [d['question'] for d in data['1']['qa_pairs']]\n",
    "train_labels = [d['answer']['spans'][0] for d in data['1']['qa_pairs']]\n",
    "\n",
    "len(dev_inputs)\n",
    "# dev_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1d6799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take the letters at position 3 of the words in \"Dorothy Eric Mensah Moyo\" and concatenate them using a space.\n",
      "Word: Dorothy\n",
      "3rd Letter: r\n",
      "Word: Eric\n",
      "3rd Letter: i\n",
      "Word: Mensah\n",
      "3rd Letter: n\n",
      "Word: Moyo\n",
      "3rd Letter: y\n",
      "Concatenation: \n",
      "r i n y\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(train_inputs), 1)\n",
    "for id_ in idx:\n",
    "    print(train_inputs[id_])\n",
    "    words = train_inputs[id_].split(' \"')[1].split('\" ')[0].split()\n",
    "    word_list = ' '.join(words)\n",
    "    for word in words:\n",
    "        print(\"Word: %s\"%word)\n",
    "        print(\"3rd Letter: %s\"%word[2])\n",
    "    print(\"Concatenation: \\n%s\" %train_labels[id_])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f54c8e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual decomposition\n",
    "out = []\n",
    "batch_size = 10\n",
    "for chunk in tqdm.tqdm(chunks(inputs, batch_size)):\n",
    "    prompts = [x for x in chunk]\n",
    "#     print(prompts)\n",
    "    out.extend(gpt3(prompts))\n",
    "pp = np.array([1 if p.strip().lower() == l else 0 for p, l in zip(out, labels)])\n",
    "pp.sum()/len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5235b50",
   "metadata": {},
   "source": [
    "#### Dataset from decomposed prompting (List reversal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820509d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/allenai/DecomP/main/datasets/reverse/test_4_normal_words.json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "inputs = [d['question'] for d in data['alg_qa']['qa_pairs']]\n",
    "labels = [d['answer']['spans'][0] for d in data['alg_qa']['qa_pairs']]\n",
    "# len(data['1']['qa_pairs'])\n",
    "len(data['alg_qa']['qa_pairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280c88af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse the sequence \"camera, file, light bulb, notebook\".\n",
      "notebook, light bulb, file, camera\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(inputs), 1)\n",
    "for id_ in idx:\n",
    "    print(inputs[id_])\n",
    "    print(labels[id_])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "09e0afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:07,  1.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual decomposition\n",
    "out = []\n",
    "batch_size = 10\n",
    "for chunk in tqdm.tqdm(chunks(inputs, batch_size)):\n",
    "    prompts = [x for x in chunk]\n",
    "#     print(prompts)\n",
    "    out.extend(gpt3(prompts))\n",
    "pp = np.array([1 if p.strip().lower() == l else 0 for p, l in zip(out, labels)])\n",
    "pp.sum()/len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24ff32",
   "metadata": {},
   "source": [
    "#### Tasks in Self-prompt (Ofir's paper) \n",
    "Musique and 2wikimultihop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6596b876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-a426bd25b30faa3b\n",
      "WARNING:datasets.builder:Found cached dataset json (/mmfs1/home/bparan/.cache/huggingface/datasets/json/default-a426bd25b30faa3b/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff0c685ba264f88881265eddbfa05d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4834"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Musique\n",
    "data_files = {split:os.path.join(cache_dir, 'musique', 'data', 'musique_full_v1.0_%s.jsonl'%split) for split in ['train', 'dev']}\n",
    "d = datasets.load_dataset('json', data_files=data_files)\n",
    "len(d['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5aee0290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the name of the southern tip of the continent that has the country where The Legend of the Lost was filmed?\n",
      "Follow up question: where was the legend of the lost filmed\n",
      "Intermediate answer: Libya\n",
      "Follow up question: What continent is Libya located on?\n",
      "Intermediate answer: Africa\n",
      "Follow up question: what is the name of the southern tip of Africa\n",
      "Intermediate answer: Cape Agulhas\n",
      "So the final answer is Cape Agulhas\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Counter([ex['answerable'] for ex in d['dev']])\n",
    "idx = np.random.randint(0, len(d['train']), 1)\n",
    "for num, ex in enumerate(d['train']):\n",
    "    if num not in idx:\n",
    "        continue\n",
    "    print(\"Question:\", ex['question'])\n",
    "    prev_answer = None\n",
    "    for subnum, decomp in enumerate(ex['question_decomposition']):\n",
    "        if prev_answer:\n",
    "            print(\"Follow up question:\", decomp['question'].replace(\"#%d\"%subnum, prev_answer))\n",
    "        else:\n",
    "            print(\"Follow up question:\", decomp['question'])\n",
    "        print(\"Intermediate answer:\", decomp['answer'])\n",
    "        prev_answer = decomp['answer']\n",
    "    print(\"So the final answer is %s\"% ex['answer'])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-8da56daef1cdd353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /mmfs1/home/bparan/.cache/huggingface/datasets/json/default-8da56daef1cdd353/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994a86f14e7b4ebd82b85f9e7e97567b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4135677a2e432d850a6345d6fbb1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc2664edf344c02aed09ae107023b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2wikimultihop\n",
    "data_files = {split:os.path.join(cache_dir, '2wikimultihop', 'data', '%s.json'%split) for split in ['train', 'dev']}\n",
    "d = datasets.load_dataset('json', data_files=data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609e970",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Known Unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "481840a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/known_unknowns/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb065d62fbd4045b150747afbda9497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "d = datasets.load_dataset('bigbench', 'known_unknowns', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] #+ d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] #+ d['validation']['targets']\n",
    "len(d['validation']['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a515d772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What was the approximate population of Cheyenne, Wyoming in 2020?\n",
      "  choice: Unknown\n",
      "  choice: 65,000\n",
      "A:\n",
      "65,000\n",
      "----\n",
      "Q: What is a kind of bird that eats fish?\n",
      "  choice: Unknown\n",
      "  choice: Heron\n",
      "A:\n",
      "Heron\n",
      "----\n",
      "Q: How many calories worth of food does a 20-pound cat eat per day?\n",
      "  choice: Unknown\n",
      "  choice: 310 calories\n",
      "A:\n",
      "310 calories\n",
      "----\n",
      "Q: What tree’s leaf is on the Canadian flag?\n",
      "  choice: Unknown\n",
      "  choice: Maple tree\n",
      "A:\n",
      "Maple tree\n",
      "----\n",
      "Q: On what date in the past hundred years did humans collectively sleep the most?\n",
      "  choice: Unknown\n",
      "  choice: July 31, 2009\n",
      "A:\n",
      "Unknown\n",
      "----\n",
      "Q: How many hours of sleep a night is considered healthy for an adult?\n",
      "  choice: Unknown\n",
      "  choice: Between 7 and 9 hours\n",
      "A:\n",
      "Between 7 and 9 hours\n",
      "----\n",
      "Q: Who was the first person to whistle?\n",
      "  choice: Unknown\n",
      "  choice: T.J. Cummings\n",
      "A:\n",
      "Unknown\n",
      "----\n",
      "Q: What is the color of Jesse Engel's second-favorite guitar?\n",
      "  choice: Unknown\n",
      "  choice: Blue\n",
      "A:\n",
      "Unknown\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(inputs), 10)\n",
    "for id_, (inp, label) in enumerate(zip(inputs, labels)):\n",
    "#     if label[0] != 'Unknown':\n",
    "#         continue\n",
    "    if id_ not in idx:\n",
    "        continue\n",
    "    print(inp)\n",
    "    print(label[0])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e7309",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Strategy QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5222b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/strategyqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e9818265864a94abe9dd1475c9487f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "d = datasets.load_dataset('bigbench', 'strategyqa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] #+ d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] #+ d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10563606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Did Queen Elizabeth The Queen Mother and her daughter share name with Tudor queen?\n",
      "A:\n",
      "Yes. Queen Elizabeth the Queen Mother gave birth to Queen Elizabeth II in 1926. The Tudor dynasty had a number of Queens including: Mary I of England, Elizabeth I of England, and Margaret Tudor, Queen of Scots.\n",
      "----\n",
      "Q: Are selfies more dangerous than plague in modern times?\n",
      "A:\n",
      "Yes. There are an average of 7 human plague cases reported each year according to the CDC. Selfies have caused people to fall off of cliffs while trying to get the perfect picture. From October 2011 and November 2017, there were 259 selfie deaths in 137 incidents.\n",
      "----\n",
      "Q: Is 3D printing able to make adenovirus?\n",
      "A:\n",
      "No. 3D printers come with limitations in terms of precision. The standard nozzle output is about 0.4 mm. Therefore, if you are planning to print something that is below 0.4mm, you will not get a useful item. Adenoviruses are medium-sized (90–100 nm), nonenveloped (without an outer lipid bilayer) viruses with an icosahedral nucleocapsid containing a double stranded DNA genome.\n",
      "----\n",
      "Q: Is Ganymede in the Milky Way galaxy?\n",
      "A:\n",
      "Yes. Ganymede is a moon of Jupiter. Jupiter is the largest planet in our solar system. The solar system is part of the Milky Way galaxy.\n",
      "----\n",
      "Q: Could you buy Hershey's Kisses in red foil with farthings after 1960?\n",
      "A:\n",
      "No. The British farthing was made obsolete at the end of 1960. In 1962, Hershey's Kisses began to be sold in colored wrappers (such as red foil).\n",
      "----\n",
      "Q: Gandalf hypothetically defeats Rincewind in a wizard battle?\n",
      "A:\n",
      "Yes. Gandalf is a 2000 plus year old wizard that has fought orcs and spirits in Middle Earth. Rincewind is the protagonist of the Discworld series. Rincewind is a failed student at the Unseen University for wizards in Ankh-Morpork. Rincewind is described by other wizards as the magical equivalent to the number zero.\n",
      "----\n",
      "Q: Can Larry King's ex-wives form a water polo team?\n",
      "A:\n",
      "Yes. Water polo is a sport played by teams of seven competitors. Larry King has seven ex-wives.\n",
      "----\n",
      "Q: Would Stephen King fans be likely to own an image of a clown?\n",
      "A:\n",
      "Yes. Stephen King wrote a popular book called \"It\" about an evil clown. \"It\" has been made into two major films and has been merchandised.\n",
      "----\n",
      "Q: Is Phobos (moon) name origin similar to Roman god Pavor?\n",
      "A:\n",
      "Yes. Phobos (moon) derives its name from ancient Greek mythology. Phobos was the god of fear. In Roman mythology, Pavor or Terror is known as the personification of fear.\n",
      "----\n",
      "Q: Would Jimmy Vee be eligible to compete in the Paralympic Games?\n",
      "A:\n",
      "Yes. Jimmy Vee is a dwarf. Dwarfism is defined as someone who is medically short-statured. Short stature due to a bone deficiency is one of the categories for paralympic athletes.\n",
      "----\n",
      "Q: Do suburbs encourage the use of cars?\n",
      "A:\n",
      "Yes. Suburbs are generally built outside of walking distance from city centers. City centers contain jobs and stores. Suburb dwellers need to access jobs and stores to survive.\n",
      "----\n",
      "Q: Did Metallica band members cutting their hair hurt their sales?\n",
      "A:\n",
      "Yes. Metallica famously cut their hair in 1996 which caused a huge divide in their fanbase. Metallica's best selling album, The Black Album, was released in 1991 and has sold over 20 million copies. Since 1996, Metallica have released 5 studio albums. Metalica's 5 studio albums since 1996 have sold around a combined 14 million copies.\n",
      "----\n",
      "Q: Is Supreme Court of the United States analogous to High Courts of Justice of Spain?\n",
      "A:\n",
      "No. The Supreme Court of the United States is the final court ad has final say in judicial matters. The High Courts of Justice in Spain rule over single communities. The Supreme Court of Spain is the highest court in Spain and can overrule lesser courts.\n",
      "----\n",
      "Q: Could you watch Naruto and Puzzle Place on the same channel?\n",
      "A:\n",
      "No. Puzzle Place aired on PBS between 1995 and 1998. Naruto aired on Cartoon Network in 2005.\n",
      "----\n",
      "Q: Is \"A Tale of Two Cities\" a popular science novel?\n",
      "A:\n",
      "No. \"A Tale of Two Cities\" is a historical fiction novel. Popular science books focus on scientific facts presented to a mainstream audience. Fiction is not fact.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(inputs), 15)\n",
    "for id_, (inp, label) in enumerate(zip(inputs, labels)):\n",
    "#     if label[0] != 'Unknown':\n",
    "#         continue\n",
    "    if id_ not in idx:\n",
    "        continue\n",
    "    print(inp)\n",
    "    print(label[0])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ad6db",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Hindu Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfaa3e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/hindu_knowledge/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aea8172a9f64680a4a72d5780f9a9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'hindu_knowledge', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "772df63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: In Hindu mythology, the avatar of Vishnu known as Vamana asks for three pieces of land from which ruler?\n",
      "  choice: Dhritasashthra\n",
      "  choice: Virata\n",
      "  choice: Bali\n",
      "  choice: Janamejaya\n",
      "A:\n",
      "Bali\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(inputs), 1)\n",
    "for id_, (inp, label) in enumerate(zip(inputs, labels)):\n",
    "#     if label[0] != 'Unknown':\n",
    "#         continue\n",
    "    if id_ not in idx:\n",
    "        continue\n",
    "    print(inp)\n",
    "    print(label[0])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95918f",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Movie Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ce0b40e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/movie_dialog_same_or_different/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239f4a4186c741efa74790968a2c5bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'movie_dialog_same_or_different', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] #+ d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] #+ d['validation']['targets']\n",
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "02112a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a conversation between two people, but the transcript doesn't mark who said what: I doubt if a few bombs would wake up Dawn on a Sunday morning. This phoney war get's on my nerves. If we're going to have a war, I wish they'd get it started. Just ignore her, Mac. ----- In the preceding conversation, were the sentences \"If we're going to have a war, I wish they'd get it started.\" and \"Just ignore her, Mac.\" said by the same or different individuals?\n",
      "Answer:\n",
      "different\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(inputs), 1)\n",
    "for id_, (inp, label) in enumerate(zip(inputs, labels)):\n",
    "#     if label[0] != 'Unknown':\n",
    "#         continue\n",
    "    if id_ not in idx:\n",
    "        continue\n",
    "    print(inp)\n",
    "    print(label[0])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96185da6",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Code Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8b086f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/code_line_description/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd57d0c574c48fcbdb3078c5f15b29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'code_line_description', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] #+ d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] #+ d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69f7acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python code:\n",
      "j,b = False,True\n",
      "if j and b:\n",
      "    print('pass')\n",
      "else:\n",
      "    print('fail')\n",
      "\n",
      "  choice: prints fail since j is false\n",
      "  choice: since both and b are true prints pass\n",
      "  choice: combines a and b\n",
      "  choice: prints value of both a and b\n",
      "\n",
      "English language description:\n",
      "prints fail since j is false\n",
      "----\n",
      "Python code:\n",
      "numbers_list = [2, 6, 8, 10, 11, 4, 12, 7, 13, 17, 0, 3, 21]\n",
      "filtered_list = list(filter(lambda num: (num > 7), numbers_list))\n",
      "print(filtered_list)\n",
      "\n",
      "  choice: prints lambda\n",
      "  choice: returns a filtered list\n",
      "  choice: prints a list of numbers greater than 7 from numbers_list\n",
      "  choice: prints numbers from 2 to 6\n",
      "\n",
      "English language description:\n",
      "prints a list of numbers greater than 7 from numbers_list\n",
      "----\n",
      "Python code:\n",
      "if num > 5:\n",
      "    print('negative')\n",
      "else:\n",
      "    print('positive')\n",
      "\n",
      "  choice: checks if a number is greater than zero\n",
      "  choice: if number is greater than 5 prints 'negative' otherwise prints 'positive'\n",
      "  choice: assigns 'positive' or 'negative' to variable num\n",
      "  choice: checks if a number is positive or negative\n",
      "\n",
      "English language description:\n",
      "if number is greater than 5 prints 'negative' otherwise prints 'positive'\n",
      "----\n",
      "Python code:\n",
      "num = 20\n",
      "factorial = 1\n",
      "\n",
      "if num < 0:\n",
      "    print('Sorry, factorial does not exist for negative numbers')\n",
      "elif num == 0:\n",
      "    print('The factorial of 0 is 1')\n",
      "else:\n",
      "    for i in range(1,num + 1):\n",
      "        factorial = factorial*i\n",
      "    print('The factorial of',num,'is',factorial)\n",
      "\n",
      "  choice: checks if a number is positive or negative\n",
      "  choice: prints the factorial of number 20\n",
      "  choice: checks if 20 is negative number\n",
      "  choice: prints 'The factorial of 20 is 0'\n",
      "\n",
      "English language description:\n",
      "prints the factorial of number 20\n",
      "----\n",
      "Python code:\n",
      "num = int(input('Enter a number: '))\n",
      "if num > 5:\n",
      "    print('positive')\n",
      "elif num == 0:\n",
      "    print('zero')\n",
      "else:\n",
      "    print('negative')\n",
      "\n",
      "  choice: checks if a number is interger\n",
      "  choice: if input is greater than 5 prints 'positive','zero' if equal to zero and 'negative' otherwise\n",
      "  choice: checks if a number is greater than zero\n",
      "  choice: checks if a number is positive negative or zero\n",
      "\n",
      "English language description:\n",
      "if input is greater than 5 prints 'positive','zero' if equal to zero and 'negative' otherwise\n",
      "----\n",
      "Python code:\n",
      "def number_vowels(test_str):\n",
      "\n",
      "    # string of vowels\n",
      "    vowels = 'aeiou'\n",
      "    test_str = ip_str.casefold()\n",
      "    count = {}.fromkeys(vowels,0)\n",
      "\n",
      "    # count the vowels\n",
      "    for char in test_str:\n",
      "        if char in count:\n",
      "            count[char] += 1\n",
      "    return count\n",
      "\n",
      "  choice: returns a dictionary of the number of occurences of each vowel in a string\n",
      "  choice: returns the sum of all the numbers\n",
      "  choice: counts the number of characters in a string\n",
      "  choice: returns complex numbers\n",
      "\n",
      "English language description:\n",
      "returns a dictionary of the number of occurences of each vowel in a string\n",
      "----\n",
      "Python code:\n",
      "def greet(name):\n",
      "    print ('Hello', name)\n",
      "\n",
      "greet('Jack')\n",
      "\n",
      "  choice: prints 'Hello Jack'\n",
      "  choice: prints 'python 3.7'\n",
      "  choice: greets Jack\n",
      "  choice: prints 'Hello World!'\n",
      "\n",
      "English language description:\n",
      "prints 'Hello Jack'\n",
      "----\n",
      "Python code:\n",
      "a, b, c, d = True, False, False, True\n",
      "if not a or not c:\n",
      "    print('no')\n",
      "else: \n",
      "    print('yes')\n",
      "\n",
      "  choice: checks if c is true or not\n",
      "  choice: combines the strings a,b,c and d\n",
      "  choice: checks if a is true or not\n",
      "  choice: checks if one of a or c is False, then prints 'no' since c is False\n",
      "\n",
      "English language description:\n",
      "checks if one of a or c is False, then prints 'no' since c is False\n",
      "----\n",
      "Python code:\n",
      "for i in range(23):\n",
      "    print(i)\n",
      "\n",
      "  choice: prints 'hello world' to the terminal\n",
      "  choice: prints values from 1 to 10\n",
      "  choice: computes first 10 prime numbers\n",
      "  choice: prints values from 0 to 22\n",
      "\n",
      "English language description:\n",
      "prints values from 0 to 22\n",
      "----\n",
      "Python code:\n",
      "x = 5\n",
      "y = 10\n",
      "x = x ^ y\n",
      "y = x ^ y\n",
      "x = x ^ y\n",
      "\n",
      "  choice: prints x times y\n",
      "  choice: y is equal to y raised to power x\n",
      "  choice: swaps x and y\n",
      "  choice: assigns x and y value 50\n",
      "  choice: x is equal to x raised to power y\n",
      "\n",
      "English language description:\n",
      "swaps x and y\n",
      "----\n",
      "Python code:\n",
      "no_terms = 5\n",
      "n1, n2 = 0, 1\n",
      "count = 0\n",
      "while count < no_terms:\n",
      "    print(n1)\n",
      "    nth = n1 + n2\n",
      "    n1 = n2\n",
      "    n2 = nth\n",
      "    count += 1\n",
      "\n",
      "  choice: prints first 5 prime numbers\n",
      "  choice: prints sum of two numbers\n",
      "  choice: prints first 5 fibonacci numbers\n",
      "  choice: prints sum of first five numbers\n",
      "\n",
      "English language description:\n",
      "prints first 5 fibonacci numbers\n",
      "----\n",
      "Python code:\n",
      "test_str = 'aaabbbaaa'\n",
      "\n",
      "# make test_string caseless\n",
      "test_str = test_str.casefold()\n",
      "\n",
      "# reverse the string\n",
      "rev_str = reversed(test_str)\n",
      "\n",
      "if list(test_str) == list(rev_str):\n",
      "    print('palindrome')\n",
      "else:\n",
      "    print('not palindrome')\n",
      "\n",
      "  choice: prints 'palindrome' since aaabbbaaa is a palindrome\n",
      "  choice: slices the string\n",
      "  choice: checks if a string has vowels\n",
      "  choice: prints string 'baTTab' 10 times\n",
      "\n",
      "English language description:\n",
      "prints 'palindrome' since aaabbbaaa is a palindrome\n",
      "----\n",
      "Python code:\n",
      "numbers_list = [2, 6, 8, 10, 11, 4, 12, 7, 13, 17, 0, 3, 21]\n",
      "remainder_list = list(map(lambda num: num % 2, numbers_list))\n",
      "print(remainder_list)\n",
      "\n",
      "  choice: prints factors of 2\n",
      "  choice: returns multiples of 3\n",
      "  choice: prints a list of remainders of numbers in list numbers_list when divided by 2\n",
      "  choice: returns a list of odd numbers\n",
      "\n",
      "English language description:\n",
      "prints a list of remainders of numbers in list numbers_list when divided by 2\n",
      "----\n",
      "Python code:\n",
      "natural_sum = 0\n",
      "i = 100\n",
      "while(i > 0):\n",
      "    natural_sum += i\n",
      "    i -= 1\n",
      "print('The sum is', natural_sum)\n",
      "\n",
      "  choice: prints the factorial of numbers\n",
      "  choice: prints the sum of first 100 natural numbers\n",
      "  choice: prints number from 10 to 0 in ascending order\n",
      "  choice: prints the numbers from 1 to 10\n",
      "\n",
      "English language description:\n",
      "prints the sum of first 100 natural numbers\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(inputs), 15)\n",
    "for id_, (inp, label) in enumerate(zip(inputs, labels)):\n",
    "#     if label[0] != 'Unknown':\n",
    "#         continue\n",
    "    if id_ not in idx:\n",
    "        continue\n",
    "    print(inp)\n",
    "    print(label[0])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1700ed",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - conceptual_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0dd73e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/conceptual_combinations/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8983b17e560642d6abc8c34ae2f6c897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'conceptual_combinations', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d0c89bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept: folding companies. Question: Which of the following sentences best characterizes folding companies?\n",
      " option: Folding companies contribute to unemployment.\n",
      " option: Folding companies produce folds.\n",
      " option: Folding companies can fit in small spaces.\n",
      " option: Folding companies manufacture origami.\n",
      "Answer:\n",
      "Folding companies contribute to unemployment.\n",
      "----\n",
      "Concept: hissing tires. Question: Which of the following sentences best characterizes hissing tires?\n",
      " option: Hissing tires are to be expected in warm weather.\n",
      " option: Hissing tires disapprove of your driving.\n",
      " option: Hissing tires are designed by sound engineers.\n",
      " option: Hissing tires are unsafe for driving.\n",
      "Answer:\n",
      "Hissing tires are unsafe for driving.\n",
      "----\n",
      "Concept: Wicked witches. Question: Which of the following sentences best characterizes wicked witches?\n",
      " option: Wicked witches eat all the sugar.\n",
      " option: Wicked witches wear white gowns.\n",
      " option: Wicked witches are skateboarders with magical powers.\n",
      " option: Wicked witches poison princesses.\n",
      "Answer:\n",
      "Wicked witches poison princesses.\n",
      "----\n",
      "Concept: boulder-sized diamond. Question: Which of the following sentences best characterizes boulder-sized diamonds?\n",
      " option: Boulder-sized diamonds are diamond-shaped rocks.\n",
      " option: Boulder-sized diamonds would be extremely valuable.\n",
      " option: Boulder-sized diamonds are desirable in engagement rings.\n",
      " option: Boulder-sized diamonds are found on ski hills.\n",
      "Answer:\n",
      "Boulder-sized diamonds would be extremely valuable.\n",
      "----\n",
      "The word 'muphe' is an adjective for things that are magnetic. Question: Which of the following sentences best characterizes muphe poles?\n",
      " option: Muphe poles eat cabbage rolls.\n",
      " option: Skiers use muphe poles.\n",
      " option: Muphe poles are very cold.\n",
      " option: Muphe poles have positive or negative charge.\n",
      "Answer:\n",
      "Muphe poles have positive or negative charge.\n",
      "----\n",
      "The word 'ulort' is an adjective for things that are underwear. Question: Which of the following sentences best characterizes ulort boxers?\n",
      " option: Ulort boxers lie on bathroom floors.\n",
      " option: Ulort boxers lie unopened.\n",
      " option: Ulort boxers lie in the sun.\n",
      " option: Ulort boxers lie to the media.\n",
      "Answer:\n",
      "Ulort boxers lie on bathroom floors.\n",
      "----\n",
      "The word 'frabgous' is an adjective for things that are joyous and respectful. Question: Which of the following sentences best characterizes frabjous funerals?\n",
      " option: New Orleans is known for its frabgous funerals.\n",
      " option: People in frabgous funerals laugh at the deceased.\n",
      " option: Frabgous funerals are sad and boring.\n",
      " option: People go to frabgous funerals to club.\n",
      "Answer:\n",
      "New Orleans is known for its frabgous funerals.\n",
      "----\n",
      "The word 'dax' is an adjective for things designed to have big holes in their surfaces. Question: Which of the following sentences best characterizes dax chairs?\n",
      " option: Dax chairs do not sell well.\n",
      " option: The value of dax chairs depends on investor confidence.\n",
      " option: Dax chairs are comfortable.\n",
      " option: Dax chairs have many responsibilities.\n",
      "Answer:\n",
      "Dax chairs do not sell well.\n",
      "----\n",
      "The word 'vart' is an adjective for things that seek out bad smells. Question: Which of the following sentences best characterizes vart husbands?\n",
      " option: Vart husbands are very handsome.\n",
      " option: Vart husbands write bad cheques.\n",
      " option: Vart husbands always take out the garbage.\n",
      " option: Vart husbands cheat on their wives.\n",
      "Answer:\n",
      "Vart husbands always take out the garbage.\n",
      "----\n",
      "Concept: Colourless red surfaces. Question: Which of the following sentences best characterizes colourless red surfaces?\n",
      " option: Colourless red surfaces are good tabletops for kitchens.\n",
      " option: Colourless red surfaces cannot exist.\n",
      " option: Colourless red surfaces are both red and green.\n",
      " option: Colourless red surfaces are used often in interior decoration.\n",
      "Answer:\n",
      "Colourless red surfaces cannot exist.\n",
      "----\n",
      "Concept: Extroverted introvert. Question: Which of the following sentences best characterizes extroverted introverts?\n",
      " option: Extroverted introverts are friendly but like to be alone.\n",
      " option: Extroverted introverts turn themselves inside-out.\n",
      " option: Extroverted introverts are B-list celebrities.\n",
      " option: Extroverted introverts should never meet strangers in public places.\n",
      "Answer:\n",
      "Extroverted introverts are friendly but like to be alone.\n",
      "----\n",
      "Concept: sliced apples. Question: Which of the following sentences best characterizes sliced apples?\n",
      " option: Sliced apples are dysfunctional.\n",
      " option: Sliced apples tend to bleed a lot.\n",
      " option: Sliced apples are cooked in a pie.\n",
      " option: Sliced apples are very sharp.\n",
      "Answer:\n",
      "Sliced apples are cooked in a pie.\n",
      "----\n",
      "The word 'frumious' is an adjective for things that are very threatening. Question: Which of the following sentences best characterizes frumious pets?\n",
      " option: Frumious pets are great companions for little children.\n",
      " option: Most people prefer frumious pets over puppies.\n",
      " option: Frumious pets are easy to recycle.\n",
      " option: If you want a frumious pet, a rattlesnake is a good choice.\n",
      "Answer:\n",
      "If you want a frumious pet, a rattlesnake is a good choice.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(inputs), 15)\n",
    "for id_, (inp, label) in enumerate(zip(inputs, labels)):\n",
    "#     if label[0] != 'Unknown':\n",
    "#         continue\n",
    "    if id_ not in idx:\n",
    "        continue\n",
    "    print(inp)\n",
    "    print(label[0])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3886ba87",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - language_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2eb4fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/language_identification (download: Unknown size, generated: 14.10 MiB, post-processed: Unknown size, total: 14.10 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/language_identification/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/language_identification/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930f17d5643143e4a7b5c86c2cb34a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'language_identification', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f431c8",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - vitaminc_fact_verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "63360ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/vitaminc_fact_verification/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356f62b39fb547b799987573e1aff524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'vitaminc_fact_verification', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c4fb3369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: Boeing 787 Dreamliner: The aircraft 's initial designation was the 7E7 , prior to its renaming in January 2005 .\n",
      "Claim: Boeing 787 Dreamliner has always had the same name .\n",
      "True, False, or Neither?\n",
      "False\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: Golden Horseshoe: The primary airport of the region is Toronto Pearson International Airport ( officially Lester B. Pearson International Airport ) , located in Mississauga , which is the busiest in Canada and the 33rd busiest in the world , handling over 41 million passengers in 2015 , and offering non-stop flights worldwide .\n",
      "Claim: The Toronto Pearson International Airport is the 34th busiest airport in the world , having less than 40 million passengers in 2014 .\n",
      "True, False, or Neither?\n",
      "False\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: They Live: The meeting is raided by police , who kill several anti-alien activists ; Nada and Frank use a stolen alien wristwatch to escape through a portal , entering the aliens ' secret command center .\n",
      "Claim: In They Live , the activists killed are anti-alien .\n",
      "True, False, or Neither?\n",
      "True\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: Indian National Congress: It was founded in Bombay in late December 1885 , during the British Raj in India .\n",
      "Claim: The Indian National Congress was founded in New Delhi .\n",
      "True, False, or Neither?\n",
      "False\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: Jack the Giant Slayer: As time passes , the magic crown is crafted into St Edward 's Crown and is secured in the Tower of London , while the legend of Jack and the giants lives on.\n",
      "Claim: The legend of Jack and the giants survived the test of time in Jack the Giant Slayer .\n",
      "True, False, or Neither?\n",
      "True\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: The Last Song -LRB-film-RRB-: Filming of `` Part of The Last Song '' lasted from June 15 to August 18 , 2009 , with much of it occurring on a studio set .\n",
      "Claim: Part of The Last Song ( film ) was filmed on a pier .\n",
      "True, False, or Neither?\n",
      "False\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: New Super Mario Bros.: is a 2006 side-scrolling platform video game developed and published by Nintendo for the Nintendo DS .\n",
      "Claim: New Super Mario Bros. is developed for the Nintendo DS handheld game console .\n",
      "True, False, or Neither?\n",
      "Neither\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: RedOne: As a producer and songwriter , he has worked with many high profile recording artists , most notably Lady Gaga , Michael Jackson , U2 , Nicki Minaj , Jennifer Lopez , Pitbull , Enrique Iglesias , Shakira , Wyclef Jean , Mariah Carey , Paulina Rubio , Mylène Farmer , Inna , Alexandra Burke , Austin Mahone , One Direction , Marc Anthony , The Band Perry , Prince Royce , Rod Stewart , among many others .\n",
      "Claim: RedOne has worked with many high-profile recording artists , including Ayumi Hamasaki .\n",
      "True, False, or Neither?\n",
      "Neither\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: Thrift Shop: The music video has garnered over 800 million views on YouTube .\n",
      "Claim: Thrift Shop has over 810 million views on YouTube .\n",
      "True, False, or Neither?\n",
      "False\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: 2020 coronavirus pandemic in Africa: As of 27 March there have been no reported cases in Comoros .\n",
      "Claim: Comoros had no reported coronavirus cases as of before 1 April .\n",
      "True, False, or Neither?\n",
      "True\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: Happy Death Day: Happy Death Day grossed $ 55.7 million in the United States and Canada , and $ 67 million in other territories , for a worldwide total of $ 122.6 million , against a production budget of $ 4.8 million .\n",
      "Claim: Happy Death Day earned less than $ 68 million outside North America and under $ 123 million worldwide .\n",
      "True, False, or Neither?\n",
      "True\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: Ted 2: Ted 2 is a 2015 American black comedy fantasy film directed by Seth MacFarlane and is a sequel to the 2012 film Ted .\n",
      "Claim: Ted 2 is a comedy .\n",
      "True, False, or Neither?\n",
      "False\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: DayZ -LRB-video game-RRB-: The development has been focused on altering the engine to suit the game 's needs , developing a working client-server architecture , and introducing new features like diseases and a better inventory system .\n",
      "Claim: Day Z has sold 3 million copies .\n",
      "True, False, or Neither?\n",
      "False\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: Blue Man Group: Blue Man Group is a performance art company formed in 1991 .\n",
      "Claim: The Blue Man Group was formed before 1989 .\n",
      "True, False, or Neither?\n",
      "False\n",
      "----\n",
      "Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\n",
      "\n",
      "\n",
      "Passage: Yeah Yeah Yeahs: The group is composed of vocalist and pianist Karen O , guitarist and keyboardist Nick Zinner kazoo player Patrick Milford , and drummer Brian Chase .\n",
      "Claim: Patrick Milford is the kazoo player for the Yeah Yeah Yeahs .\n",
      "True, False, or Neither?\n",
      "True\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(inputs), 15)\n",
    "for id_, (inp, label) in enumerate(zip(inputs, labels)):\n",
    "#     if label[0] != 'Unknown':\n",
    "#         continue\n",
    "    if id_ not in idx:\n",
    "        continue\n",
    "    print(inp)\n",
    "    print(label[0])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a1252",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - formal_fallacies_syllogisms_negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc6256df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/formal_fallacies_syllogisms_negation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86005e73746e4e8db8ed11fe6911c749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'formal_fallacies_syllogisms_negation', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c759da",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - misconceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9fd1a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/misconceptions/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64f615b26d14e9aa46fca6d01491acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'misconceptions', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f0d1ee26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\\n\\n\\nPassage: Garfield-COLON- A Tail of Two Kitties: The film received negative reviews from critics and it earned $ 141.7 million on a $ 60 million budget.\\nClaim: Garfield : A Tail of Two Kitties received bleak reviews .\\nTrue, False, or Neither?'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53cd7b2",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - logical_deduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dcf8e656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_deduction/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2f260b02844d1e874ee174b81face9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'logical_deduction', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa861e77",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - winowhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f006e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/winowhy/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d167ecfed1b41f2a0379c002ccf9ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'winowhy', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c1bd6",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - novel_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0992f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/novel_concepts/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf9c3114e3b43638b50c8b8fed9c107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'novel_concepts', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb352fb",
   "metadata": {},
   "source": [
    "#### Tasks in Auto-Cot - MAWPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9672b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration omarxadel--MaWPS-ar-e0d2ee7eb9fa6fdb\n",
      "WARNING:datasets.builder:Found cached dataset csv (/gscratch/zlab/bparan/projects/cascades/data/omarxadel___csv/omarxadel--MaWPS-ar-e0d2ee7eb9fa6fdb/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdf77d884354d5eabd8bf27ddae48d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('omarxadel/MaWPS-ar', 'test', cache_dir=cache_dir)\n",
    "inputs = [list(d.values())[0] for d in data['validation']]\n",
    "labels = []\n",
    "for d in data['validation']:\n",
    "    try:\n",
    "        ans = eval(list(d.values())[1].split(\"=\")[-1].strip())\n",
    "        if isinstance(ans, int):\n",
    "            labels.append(ans)\n",
    "        elif (ans).is_integer():\n",
    "            labels.append(int(ans))\n",
    "        else:\n",
    "            labels.append(float(\"%.2f\" % ans))\n",
    "        \n",
    "    except:\n",
    "        ans = eval(list(d.values())[1].split(\"=\")[0].strip())\n",
    "        if isinstance(ans, int):\n",
    "            labels.append(ans)\n",
    "        elif (ans).is_integer():\n",
    "            labels.append(int(ans))\n",
    "        else:\n",
    "            labels.append(float(\"%.2f\" % ans))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03939ba",
   "metadata": {},
   "source": [
    "#### Tasks in Auto-CoT (GSM8K) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "11f139ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset gsm8k (/gscratch/zlab/bparan/projects/cascades/data/gsm8k/main/1.1.0/37bfb08b1d4fcbb01f06b03d9e1ef5f1fcbd4d3af3d08842c50d7305091285ba)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780dabfe15f47658ae92531e61c310b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('gsm8k', 'main', cache_dir=cache_dir)['test']\n",
    "inputs = [d['question'] for d in data]\n",
    "labels = [d['answer'].split('#### ')[-1] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1155251",
   "metadata": {},
   "source": [
    "#### Tasks on Auto-CoT (AQUA-RAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64a68681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset aqua_rat (/gscratch/zlab/bparan/projects/cascades/data/aqua_rat/raw/0.0.0/fc47b9f437236ab96fc1fcb61096aa193819aedd76437893e2390ab0740a3381)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d954f8af98c34b8bb7ba7ce2907789ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('aqua_rat', 'raw', cache_dir=cache_dir)['validation']\n",
    "inputs = [d['question'] + \" \".join(d['options']) for d in data]\n",
    "labels = [d['correct'] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c2fb3",
   "metadata": {},
   "source": [
    "#### Tasks on Auto-CoT (Commonsense QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "709b807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset commonsense_qa (/gscratch/zlab/bparan/projects/cascades/data/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e3e472d0d54b2e92afdc1b3e8a7fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('commonsense_qa', cache_dir=cache_dir)['validation']\n",
    "inputs = [d['question']+ \" \" + \" \".join([k + \") \" + v for k, v in zip(d['choices']['label'], d['choices']['text'])]) for d in data]\n",
    "labels = [d['answerKey'] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d6ee6",
   "metadata": {},
   "source": [
    "#### AMA Tasks (From Super-Glue they include boolQ, cb, copa, multirc, record, rte, wsc, WiC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "accca089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset super_glue (/gscratch/zlab/bparan/projects/cascades/data/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a1bb22af8e477e9ec2f0f9cf946ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BoolQ\n",
    "data = datasets.load_dataset('super_glue', 'boolq', cache_dir=cache_dir)['validation']\n",
    "inputs = [d['passage']+ \" \" + d['question'][0].title() + d['question'][1:]  + \"?\" for d in data]\n",
    "label_dict = {0:'False', 1:'True'}\n",
    "labels = [label_dict[d['label']] for d in data]\n",
    "# Similar transformations to be made for other Superglue tasks: cb, copa, multirc, record, rte, wsc, wic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fc8249",
   "metadata": {},
   "source": [
    "#### AMA Tasks (From Adversarial NLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4e7cd285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset anli (/gscratch/zlab/bparan/projects/cascades/data/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f106af0947424b2e9ec8b9294df88e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Can also look at dev_r2, dev_r2\n",
    "data = datasets.load_dataset('anli', cache_dir=cache_dir)['dev_r3']\n",
    "inputs = [\"Sentence1: \" + d['premise'] + \"\\nSentence2: \" +d['hypothesis'] for d in data]\n",
    "label_dict = {0:\"entailment\", 1:'neutral', 2:'contradiction'}\n",
    "labels = [label_dict[d['label']] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad5715",
   "metadata": {},
   "source": [
    "#### Flipped Learning tasks Storycloze, PIQA, HellaSwag, ARC challenge and openbookQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f5368aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-fe6cd1e9646dcb63\n",
      "WARNING:datasets.builder:Found cached dataset story_cloze (/mmfs1/home/bparan/.cache/huggingface/datasets/story_cloze/default-fe6cd1e9646dcb63/0.0.0/45cead0538c3deb72d731a7990e60835c2c9c5d5d5b1e95a7dd47ccf593671e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf21029b5c6b494481fb35c41adfe0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1571"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# story_cloze\n",
    "validation_path = os.path.join(cache_dir, 'story_cloze') #, 'cloze_test_val__winter2018-cloze_test_ALL_val - 1 - 1.csv')\n",
    "data = datasets.load_dataset('story_cloze', data_dir=validation_path)\n",
    "len(data['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec7cbefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset piqa (/gscratch/zlab/bparan/projects/cascades/data/piqa/plain_text/1.1.0/6c611c1a9bf220943c4174e117d3b660859665baf1d43156230116185312d011)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e625aaa1a33f4aa5a7cec2a9d4954b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'goal': \"How do I ready a guinea pig cage for it's new occupants?\",\n",
       " 'sol1': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped paper strips, you will also need to supply it with a water bottle and a food dish.',\n",
       " 'sol2': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped jeans material, you will also need to supply it with a water bottle and a food dish.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_dataset('piqa', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6907a811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset hellaswag (/gscratch/zlab/bparan/projects/cascades/data/hellaswag/default/0.1.0/c37cd37196278995f42bc32f532730ae9b0d5f0f4a2d3b97735c17ff3ad67169)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a231850553404ebdbeaf25e8a4166354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ind': 24,\n",
       " 'activity_label': 'Roof shingle removal',\n",
       " 'ctx_a': 'A man is sitting on a roof.',\n",
       " 'ctx_b': 'he',\n",
       " 'ctx': 'A man is sitting on a roof. he',\n",
       " 'endings': ['is using wrap to wrap a pair of skis.',\n",
       "  'is ripping level tiles off.',\n",
       "  \"is holding a rubik's cube.\",\n",
       "  'starts pulling up roofing on a roof.'],\n",
       " 'source_id': 'activitynet~v_-JhWjGDPHMY',\n",
       " 'split': 'val',\n",
       " 'split_type': 'indomain',\n",
       " 'label': '3'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_dataset('hellaswag', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8def24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset ai2_arc (/gscratch/zlab/bparan/projects/cascades/data/ai2_arc/ARC-Challenge/1.0.0/1569c2591ea2683779581d9fb467203d9aa95543bb9b75dcfde5da92529fd7f6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a353e805f44e4965b3e840fa05804e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_412337',\n",
       " 'question': 'During an investigation, heat transferred from a liquid to the environment. Which pair of explanations can best account for this result?',\n",
       " 'choices': {'text': ['The temperature of the liquid increased, or the liquid became a gas.',\n",
       "   'The temperature of the liquid increased, or the liquid became a solid.',\n",
       "   'The temperature of the liquid decreased, or the liquid became a gas.',\n",
       "   'The temperature of the liquid decreased, or the liquid became a solid.'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'D'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is also the ARC-easy split\n",
    "data = datasets.load_dataset('ai2_arc', 'ARC-Challenge', cache_dir=cache_dir)['validation']\n",
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "87329332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5241b9dc876d4572bee8121deb5fc4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3228d8deb10248c4a2d830349d7d0f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset openbookqa (/gscratch/zlab/bparan/projects/cascades/data/openbookqa/main/1.0.1/f338ccacfbc86fb8c2de3aa1c06d2ce686933de3bca284dba97d32592c52b33f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d112a726b12944f7a2f5e5633b12589a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '8-376',\n",
       " 'question_stem': 'Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as',\n",
       " 'choices': {'text': ['Deep sea animals',\n",
       "   'fish',\n",
       "   'Long Sea Fish',\n",
       "   'Far Sea Animals'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'A'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenbookQa\n",
    "data = datasets.load_dataset('openbookqa', 'main', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f35b9a",
   "metadata": {},
   "source": [
    "#### Other tasks from AMA (Classification) : Agnews, DBPedia, Amazon movie reivew and SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f80cbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset ag_news (/gscratch/zlab/bparan/projects/cascades/data/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbb2225e2ca4e1bab24ed464e8dce89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## For others use the strings : dbpedia_14, sst2\n",
    "data = datasets.load_dataset('ag_news', cache_dir=cache_dir)['test']\n",
    "inputs = [d['text'] for d in data]\n",
    "label_dict = {0:'World', 1:'Sports', 2:'Business', 3: 'Sci/Tech'}\n",
    "labels = [label_dict[d['label']] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4a0cae",
   "metadata": {},
   "source": [
    "#### Tasks from reframing natural language instructions\n",
    "\n",
    "MC-Taco (question generation), QASC (question generation), Quoref, Winogrande, CosmosQA, MultiRC, MC-TACO (Incorrect answer generation for duration and transcience questions), QASC (overlapping words), Essential terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "74424eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download natural instructions\n",
    "\n",
    "def transform_example(example):\n",
    "    # Very simple transformation of the example\n",
    "    return example[\"input\"] + \"\\n\" + example[\"output\"]\n",
    "\n",
    "NQ_REWRITE_TASKS = ['task003_mctaco_question_generation_event_duration.json', \n",
    "           'task040_qasc_question_generation.json',\n",
    "           'task002_quoref_answer_generation.json',\n",
    "           'task033_winogrande_answer_generation.json',\n",
    "           'task024_cosmosqa_answer_generation.json',\n",
    "           'task056_multirc_classify_correct_answer.json',\n",
    "           'task005_mctaco_wrong_answer_generation_event_duration.json', \n",
    "           'task008_mctaco_wrong_answer_generation_transient_stationary.json',\n",
    "           'task039_qasc_find_overlapping_words.json',\n",
    "           'task044_essential_terms_identifying_essential_words.json']\n",
    "for task_name in NQ_REWRITE_TASKS:\n",
    "    nq_path = \"/mmfs1/gscratch/zlab/bparan/projects/cascades/src/natural-instructions/tasks\"\n",
    "    task_path = os.path.join(nq_path, task_name)\n",
    "    task_data = json.loads(open(task_path).read())\n",
    "    instances = []\n",
    "    for instance in task_data[\"Instances\"]:\n",
    "        instances.append({\"guid\": instance['id'], \"input\": instance[\"input\"], \"label\": instance[\"output\"][0]})\n",
    "    instruction = task_data[\"Definition\"]\n",
    "    examples = \"\"\n",
    "    for ex in task_data[\"Positive Examples\"]:\n",
    "        examples += transform_example(ex)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a0ad4",
   "metadata": {},
   "source": [
    "#### Additional promising datasets from BigBench\n",
    "\n",
    "* Word Sorting\n",
    "* Word Unscrambling\n",
    "* Which Wikipedia Edit\n",
    "* Unnatural incontext learning\n",
    "* Unit Interpretation\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99d6134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/word_sorting (download: Unknown size, generated: 959.64 KiB, post-processed: Unknown size, total: 959.64 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/word_sorting/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/word_sorting/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16adfc0207714c8582c435bed8c2445c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'word_sorting', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0162585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/word_unscrambling/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c4141876d94939b7738d2850e77fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'word_unscrambling', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f3fe92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/which_wiki_edit (download: Unknown size, generated: 12.08 MiB, post-processed: Unknown size, total: 12.08 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/which_wiki_edit/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/571 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/which_wiki_edit/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5714efc4fe146b295f7e9665c350d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'which_wiki_edit', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9208e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/unnatural_in_context_learning/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f8a03634984b10a9c4375f5be5dacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'unnatural_in_context_learning', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7acf88ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/unit_interpretation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'unit_interpretation', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5da9044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/understanding_fables (download: Unknown size, generated: 445.17 KiB, post-processed: Unknown size, total: 445.17 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/understanding_fables/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/37 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/understanding_fables/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'understanding_fables', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71358ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/tracking_shuffled_objects/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172a65b1213747579a998872a1108ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'tracking_shuffled_objects', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd4f9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/temporal_sequences (download: Unknown size, generated: 1.31 MiB, post-processed: Unknown size, total: 1.31 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/temporal_sequences/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/temporal_sequences/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'temporal_sequences', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1fdb314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/symbol_interpretation (download: Unknown size, generated: 2.19 MiB, post-processed: Unknown size, total: 2.19 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/symbol_interpretation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/795 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/symbol_interpretation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 09:34:18.109367: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-10-13 09:34:18.131926: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da52de51349f4c0bba292d0359fbb4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'symbol_interpretation', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d2a38c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/sufficient_information/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec7a8008c6d4aec94fa1fc7e9f9b69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'sufficient_information', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad7eefb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/sports_understanding (download: Unknown size, generated: 443.48 KiB, post-processed: Unknown size, total: 443.48 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/sports_understanding/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/986 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: sports_understanding has 14 duplicate examples out of 1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/197 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/sports_understanding/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'sports_understanding', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58ec466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/snarks (download: Unknown size, generated: 89.50 KiB, post-processed: Unknown size, total: 89.50 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/snarks/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/145 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/snarks/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'snarks', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0c306be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/simple_text_editing (download: Unknown size, generated: 54.52 KiB, post-processed: Unknown size, total: 54.52 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/simple_text_editing/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/simple_text_editing/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 09:50:32.037137: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'simple_text_editing', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7424855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/sentence_ambiguity (download: Unknown size, generated: 16.07 KiB, post-processed: Unknown size, total: 16.07 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/sentence_ambiguity/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 09:54:48.161775: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/sentence_ambiguity/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 09:54:48.245917: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'sentence_ambiguity', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "866003ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/salient_translation_error_detection (download: Unknown size, generated: 2.18 MiB, post-processed: Unknown size, total: 2.18 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/salient_translation_error_detection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/salient_translation_error_detection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'salient_translation_error_detection', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4fdf315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/riddle_sense (download: Unknown size, generated: 30.43 KiB, post-processed: Unknown size, total: 30.43 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/riddle_sense/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/49 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/33 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 10:15:59.806252: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/riddle_sense/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 10:15:59.889900: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'riddle_sense', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "992e2dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/repeat_copy_logic (download: Unknown size, generated: 13.13 KiB, post-processed: Unknown size, total: 13.13 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/repeat_copy_logic/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 10:18:25.874866: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/repeat_copy_logic/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 10:18:25.961445: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'repeat_copy_logic', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08f7f45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/reasoning_about_colored_objects (download: Unknown size, generated: 1.74 MiB, post-processed: Unknown size, total: 1.74 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/reasoning_about_colored_objects/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/reasoning_about_colored_objects/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'reasoning_about_colored_objects', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2fbcb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/real_or_fake_text (download: Unknown size, generated: 102.39 MiB, post-processed: Unknown size, total: 102.39 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/real_or_fake_text/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/15088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12072 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/real_or_fake_text/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'real_or_fake_text', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e4480f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/question_selection (download: Unknown size, generated: 4.75 MiB, post-processed: Unknown size, total: 4.75 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/question_selection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1582 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: question_selection has 8 duplicate examples out of 1590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1266 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/316 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/question_selection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'question_selection', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cb31a408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/presuppositions_as_nli (download: Unknown size, generated: 982.28 KiB, post-processed: Unknown size, total: 982.28 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/presuppositions_as_nli/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/147 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/presuppositions_as_nli/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'presuppositions_as_nli', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "21035ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/physics_questions (download: Unknown size, generated: 35.98 KiB, post-processed: Unknown size, total: 35.98 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/physics_questions/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/54 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/physics_questions/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:47:28.847296: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa40f8d49b14c5a98cd0535daf02dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'physics_questions', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d84c618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/physical_intuition/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'physical_intuition', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "80850d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/penguins_in_a_table/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89671cbe6e2c4be8805818f95e22aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'penguins_in_a_table', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "211b8771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/operators (download: Unknown size, generated: 63.48 KiB, post-processed: Unknown size, total: 63.48 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/operators/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: operators has 1 duplicate examples out of 211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/168 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/operators/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'operators', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "eade5467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/odd_one_out (download: Unknown size, generated: 27.24 KiB, post-processed: Unknown size, total: 27.24 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/odd_one_out/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/86 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/69 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/odd_one_out/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 12:57:57.267219: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'odd_one_out', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5ed750a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/object_counting (download: Unknown size, generated: 292.43 KiB, post-processed: Unknown size, total: 292.43 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/object_counting/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/object_counting/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'object_counting', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2a389f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/novel_concepts/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59f51a5717d473ba61f21cdb18b4083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'novel_concepts', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b6425be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/nonsense_words_grammar/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'nonsense_words_grammar', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5376a9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/navigate (download: Unknown size, generated: 441.84 KiB, post-processed: Unknown size, total: 441.84 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/navigate/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/navigate/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'navigate', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0d3d43c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/modified_arithmetic (download: Unknown size, generated: 2.33 MiB, post-processed: Unknown size, total: 2.33 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/modified_arithmetic/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/modified_arithmetic/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'modified_arithmetic', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bcacbfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/minute_mysteries_qa (download: Unknown size, generated: 6.19 MiB, post-processed: Unknown size, total: 6.19 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/minute_mysteries_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/94 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/minute_mysteries_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'minute_mysteries_qa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ee651dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/metaphor_boolean (download: Unknown size, generated: 418.24 KiB, post-processed: Unknown size, total: 418.24 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/metaphor_boolean/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/680 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/544 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/136 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/metaphor_boolean/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'metaphor_boolean', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "efdcd266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/logical_sequence (download: Unknown size, generated: 44.50 KiB, post-processed: Unknown size, total: 44.50 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_sequence/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/39 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 14:10:53.155483: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 14:10:53.242602: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_sequence/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 14:10:53.324030: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'logical_sequence', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "87b1969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/logical_fallacy_detection (download: Unknown size, generated: 1.38 MiB, post-processed: Unknown size, total: 1.38 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_fallacy_detection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2240 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/560 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_fallacy_detection/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d5331cb6ce4d5db24803403a6070c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'logical_fallacy_detection', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f272d6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_deduction/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'logical_deduction', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b3135195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/logical_args (download: Unknown size, generated: 85.24 KiB, post-processed: Unknown size, total: 85.24 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_args/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/32 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 20:52:20.466628: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 20:52:20.564030: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 20:52:20.662655: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/logical_args/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'logical_args', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6d3b3cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/linguistics_puzzles (download: Unknown size, generated: 3.33 MiB, post-processed: Unknown size, total: 3.33 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/linguistics_puzzles/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/linguistics_puzzles/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'linguistics_puzzles', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "58efa4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/language_games/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ece20a1aa447d8804ddd78eb6008b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# physics too\n",
    "d = datasets.load_dataset('bigbench', 'language_games', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c93d7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/intent_recognition (download: Unknown size, generated: 631.06 KiB, post-processed: Unknown size, total: 631.06 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/intent_recognition/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/693 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/555 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/intent_recognition/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'intent_recognition', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "7beb5bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/implicit_relations (download: Unknown size, generated: 156.30 KiB, post-processed: Unknown size, total: 156.30 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/implicit_relations/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/85 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/implicit_relations/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'implicit_relations', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d7732513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/implicatures (download: Unknown size, generated: 179.50 KiB, post-processed: Unknown size, total: 179.50 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/implicatures/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/492 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/implicatures/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'implicatures', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "348cf453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/11.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/284k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/identify_odd_metaphor (download: Unknown size, generated: 54.04 KiB, post-processed: Unknown size, total: 54.04 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/identify_odd_metaphor/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/47 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 20:43:27.791681: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/31 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/identify_odd_metaphor/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 20:43:27.967707: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'identify_odd_metaphor', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "80b49c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/hyperbaton (download: Unknown size, generated: 17.93 MiB, post-processed: Unknown size, total: 17.93 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/hyperbaton/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/hyperbaton/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'hyperbaton', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d9cf628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/formal_fallacies_syllogisms_negation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'formal_fallacies_syllogisms_negation', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3d3181fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/few_shot_nlg (download: Unknown size, generated: 148.44 KiB, post-processed: Unknown size, total: 148.44 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/few_shot_nlg/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/123 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/few_shot_nlg/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'few_shot_nlg', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "69f524e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/evaluating_information_essentiality (download: Unknown size, generated: 151.52 KiB, post-processed: Unknown size, total: 151.52 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/evaluating_information_essentiality/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/evaluating_information_essentiality/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 12:47:46.684679: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'evaluating_information_essentiality', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "22c9f57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/epistemic_reasoning (download: Unknown size, generated: 1.69 MiB, post-processed: Unknown size, total: 1.69 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/epistemic_reasoning/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/epistemic_reasoning/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'epistemic_reasoning', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e88ae07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/empirical_judgments/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d58e1c98e3411d8af1821295812035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'empirical_judgments', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d8924459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/elementary_math_qa (download: Unknown size, generated: 25.69 MiB, post-processed: Unknown size, total: 25.69 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/elementary_math_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/38160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: elementary_math_qa:language_hint_only has 140 duplicate examples out of 7688\n",
      "warning: elementary_math_qa:mathematical_hint_only has 140 duplicate examples out of 7688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/30531 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/7629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/elementary_math_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'elementary_math_qa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "3c73d8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/discourse_marker_prediction (download: Unknown size, generated: 3.99 MiB, post-processed: Unknown size, total: 3.99 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/discourse_marker_prediction/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/857 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/686 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/171 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/discourse_marker_prediction/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'discourse_marker_prediction', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6602cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/disambiguation_qa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'disambiguation_qa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "39ef89de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/date_understanding (download: Unknown size, generated: 186.06 KiB, post-processed: Unknown size, total: 186.06 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/date_understanding/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/date_understanding/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'date_understanding', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "7bb03721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/cs_algorithms (download: Unknown size, generated: 533.76 KiB, post-processed: Unknown size, total: 533.76 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/cs_algorithms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/1320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1056 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/cs_algorithms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'cs_algorithms', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8dc74cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/crash_blossom (download: Unknown size, generated: 23.93 KiB, post-processed: Unknown size, total: 23.93 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/crash_blossom/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:45:16.755606: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/crash_blossom/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:45:16.841486: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'crash_blossom', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "39ec858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/contextual_parametric_knowledge_conflicts (download: Unknown size, generated: 27.84 MiB, post-processed: Unknown size, total: 27.84 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/contextual_parametric_knowledge_conflicts/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/17528 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14023 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3505 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/contextual_parametric_knowledge_conflicts/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'contextual_parametric_knowledge_conflicts', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "e845741b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/conceptual_combinations/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'conceptual_combinations', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "27056f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/common_morpheme/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'common_morpheme', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "837d7c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/codenames (download: Unknown size, generated: 49.31 KiB, post-processed: Unknown size, total: 49.31 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/codenames/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/85 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/68 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/17 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/codenames/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:49:50.762256: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'codenames', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "29e888a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/bridging_anaphora_resolution_barqa (download: Unknown size, generated: 3.76 MiB, post-processed: Unknown size, total: 3.76 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'bridging_anaphora_resolution_barqa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "308701b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/bridging_anaphora_resolution_barqa (download: Unknown size, generated: 3.76 MiB, post-processed: Unknown size, total: 3.76 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'analogical_similarity', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "158ae193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/bridging_anaphora_resolution_barqa (download: Unknown size, generated: 3.76 MiB, post-processed: Unknown size, total: 3.76 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/bridging_anaphora_resolution_barqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'abstract_narrative_understanding', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "eaf87c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/auto_debugging (download: Unknown size, generated: 10.08 KiB, post-processed: Unknown size, total: 10.08 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/auto_debugging/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/34 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/auto_debugging/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:52:31.091462: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3f0bc0b1f54b1e9489ee213f58ab89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# international_phonetic_alphabet_transliterate too \n",
    "d = datasets.load_dataset('bigbench', 'auto_debugging', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "cf4205bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "if x < 5:\n",
      "\tpass\n",
      "```\n",
      "What error does this program surface?\n",
      "[\"NameError: name 'x' is not defined\"]\n",
      "----------\n",
      "\n",
      "```\n",
      "d = {1: 'hello', 2: 'bye', 3: 'good morning'}\n",
      "str_ = ''\n",
      "for i in range(len(d)):\n",
      "\tif i % 2 == 1:\n",
      "\t\tstr_ += d[i]\n",
      "```\n",
      "What is the value of str_ after this program executes?\n",
      "['hellogood morning']\n",
      "----------\n",
      "\n",
      "```\n",
      "class MyClass():\n",
      "\tdef __init__(self, param):\n",
      "\t\tself.param = param\n",
      "x = MyClass(5)\n",
      "y = MyClass(x.param)\n",
      "```\n",
      "What is the value of x.param at the end of this program?\n",
      "['5']\n",
      "----------\n",
      "\n",
      "```\n",
      "def sq(x):\n",
      "\treturn x*x\n",
      "y = sq(5)\n",
      "x = sq(3)\n",
      "```\n",
      "What is the value of x at the end of this program?\n",
      "['9']\n",
      "----------\n",
      "\n",
      "```\n",
      "class MyClass():\n",
      "\tdef __init__(self):\n",
      "\t\tprint(param)\n",
      "x = MyClass(5)\n",
      "```\n",
      "What is the value of x.param at the end of this program?\n",
      "['None']\n",
      "----------\n",
      "\n",
      "```\n",
      "while True\n",
      "\tprint('hello world')\n",
      "```\n",
      "What type of exception does this program produce?\n",
      "['SyntaxError: invalid syntax']\n",
      "----------\n",
      "\n",
      "```\n",
      "sum = 0\n",
      "for i in range(100):\n",
      "\tsum += i\n",
      "```\n",
      "What is the value of sum immediately after the 10th time line 3 is executed?\n",
      "['45']\n",
      "----------\n",
      "\n",
      "```\n",
      "y = list(map(int, ['1', 'hello', '2']))\n",
      "```\n",
      "What error does this program produce?\n",
      "[\"ValueError: invalid literal for int() with base 10: 'hello'\"]\n",
      "----------\n",
      "\n",
      "```\n",
      "sum = 0\n",
      "for i in range(100, 0, -2):\n",
      "\tsum += i\n",
      "```\n",
      "What is the value of sum at the end of this program?\n",
      "['2550']\n",
      "----------\n",
      "\n",
      "```\n",
      "def sq(x):\n",
      "\treturn x*x\n",
      "y = sq(5)\n",
      "x = sq(y)\n",
      "```\n",
      "What is the value of x at the end of this program?\n",
      "['625']\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(inputs[i])\n",
    "    print(labels[i])\n",
    "    print('-'*10 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fb052ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7854"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
