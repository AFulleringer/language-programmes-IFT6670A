{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a803c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 15:09:13.691840: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-12 15:09:18.739153: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-12 15:09:18.739174: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "with open(os.path.expanduser('~/.openai_api_key'), 'r') as file:\n",
    "    openai.api_key = file.read().replace('\\n', '')\n",
    "\n",
    "import adatest\n",
    "import re\n",
    "import json\n",
    "import jsonlines\n",
    "import seqio\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = \"/etc/ssl/certs/ca-bundle.crt\"\n",
    "from bigbench.bbseqio import tasks\n",
    "vocabulary=seqio.SentencePieceVocabulary(\"/gscratch/zlab/bparan/projects/cascades/models/t5-spiece.model\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import List\n",
    "# from utils.constants import OPENAI_API_KEY\n",
    "\n",
    "import tqdm\n",
    "\n",
    "with open(os.path.expanduser('~/.openai_api_key'), 'r') as file:\n",
    "    openai.api_key = file.read().replace('\\n', '')\n",
    "print(openai.api_key)\n",
    "\n",
    "cache_dir = '/gscratch/zlab/bparan/projects/cascades/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862d9d6",
   "metadata": {},
   "source": [
    "### GPT-3 Model for prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65579be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIModel(adatest.Model):\n",
    "    def __init__(self, model=\"text-davinci-002\", quote=\"\\\"\", temperature=0.7, top_p=1, max_length=30, n=1):\n",
    "        self.model = model\n",
    "        self.api_key = openai.api_key\n",
    "        self.quote = quote\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_length = max_length\n",
    "        self.n = n\n",
    "    def __call__(self, strings):\n",
    "        resp = openai.Completion.create(\n",
    "            model=self.model,\n",
    "            prompt=strings,\n",
    "            max_tokens=self.max_length,\n",
    "            temperature=self.temperature,\n",
    "            top_p=self.top_p,\n",
    "            n=self.n,\n",
    "            stop=self.quote,\n",
    "        )\n",
    "        return [x[\"text\"] for x in resp['choices']]\n",
    "\n",
    "gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=200, quote='', n=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a1631",
   "metadata": {},
   "source": [
    "### Prompt to propose an instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7717d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_decomposition(decomp_prompt, io_pairs, n=20):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=n)\n",
    "    prompt = '''%s. Here are examples of input-output pairs for the task I'm trying to break down.\n",
    "----\n",
    "%s\n",
    "----\n",
    "Steps:\n",
    "1.'''%(decomp_prompt, io_pairs)\n",
    "    return gpt3(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf5052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_instruction(instruct_prompt, io_pairs, n=20):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=n)\n",
    "    prompt = '''%s. Here are examples of input-output pairs for this task.\n",
    "----\n",
    "%s\n",
    "----\n",
    "I can do this task by'''%(instruct_prompt, io_pairs)\n",
    "    return gpt3(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca45444",
   "metadata": {},
   "source": [
    "### Automatic Decomposition Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2af46cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "941160e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(inputs, labels, n=100):\n",
    "    idxs = np.random.choice(len(inputs), n, replace=False)\n",
    "    labs = np.array([labels[i] for i in idxs])\n",
    "    subset = [inputs[i] for i in idxs]\n",
    "    return labs, subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1225c",
   "metadata": {},
   "source": [
    "# Tasks \n",
    "\n",
    "For each tasks, we compute:\n",
    "* Best human decomposition performance over N runs: Known decomps or ones that we come up with. A further variant of this is (a) Decompositing into individual GPT-3 calls with few-shot prompting (decompositional prompting) and (b) Making and integrating external affordance calls when needed.\n",
    "* Automatic instruction generation (APE): Reporting on top-K instructions. APE reports average over top-10 for 200 instructions. They also have an efficient score estimation technique whereby promising candidates (evaluated based on a small subset) are given more compute resource. \n",
    "* Automatic decomposition generation, followed by zero-shot application to downstream task. Reporting average performance over top-k decompositions\n",
    "* Automtic decomposition: Instruction refinement and decomposition ensembling\n",
    "* Potential affordance calls and decompsoitions with those calls. \n",
    "* Human-LLM collaborative decompositions\n",
    "\n",
    "Things to keep track of:\n",
    "* Evaluation metric computation\n",
    "* Generated sequence length "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f1095",
   "metadata": {},
   "source": [
    "#### Anachronisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c16e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/mmfs1/home/bparan/.cache/huggingface/datasets/bigbench/anachronisms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe7608bbb6746b6bd4291be7e00f002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data\n",
    "d = datasets.load_dataset('bigbench', 'anachronisms')\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = np.array([int(x[0] == 'Yes') for x in d['train']['targets'] + d['validation']['targets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "666ef707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Performance:\n",
      "Mean 0.7826086956521738\n",
      "Std. Dev 0.7826086956521738\n"
     ]
    }
   ],
   "source": [
    "# Human Decomp \n",
    "def anachronism(x):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=200, quote='---', n=1)\n",
    "    prompt = '''Given a sentence and the time periods of each entity in it, tell me if it could have happened or not.\n",
    "Sentence: I wrote about shakespeare\n",
    "Entities and dates:\n",
    "I -> 21st century\n",
    "Shakespeare -> 16th century\n",
    "Could the sentence be true based on the dates alone: Yes\n",
    "----\n",
    "Sentence: Shakespeare wrote about me\n",
    "\n",
    "Entities and dates:\n",
    "Shakespeare -> 16th century\n",
    "I -> 21st century\n",
    "\n",
    "Could the sentence be true based on the dates alone: No\n",
    "----\n",
    "Sentence: %s''' % x\n",
    "    return gpt3(prompt)\n",
    "\n",
    "perf_array = []\n",
    "runs = 2\n",
    "for run in range(runs): \n",
    "    answers = []\n",
    "    for x in inputs:\n",
    "        answers.append(anachronism(x))\n",
    "    preds = np.array([int(x[0].endswith('No')) for x in answers])\n",
    "    perf_array.append((preds == labels).mean())\n",
    "print(\"Human Performance:\")\n",
    "print(\"Mean\", np.mean(perf_array))\n",
    "print(\"Std. Dev\", np.mean(perf_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c685df6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction 0\n",
      "0.63\n",
      "Instruction 1\n",
      "0.61\n",
      "Instruction 2\n",
      "0.5\n",
      "Instruction 3\n",
      "0.58\n",
      "Instruction 4\n",
      "0.63\n",
      "Instruction 5\n",
      "0.62\n",
      "Instruction 6\n",
      "0.62\n",
      "Instruction 7\n",
      "0.58\n",
      "Instruction 8\n",
      "0.66\n",
      "Instruction 9\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "# Automatic instruction runs.\n",
    "\n",
    "instruct_prompt = 'I want to figure out whether a sentence contains anachronisms or not. An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time.'\n",
    "io_pairs = \"\"\"Input: George Washington fought in the American Civil War.\n",
    "Output: No\n",
    "Input: The Mongolian horse rider used his bow to hunt the velociraptor.\n",
    "Output: Yes\n",
    "Input: Beats from the MPC3000 helped inspire many original blues artists.\n",
    "Output: No\n",
    "Input: Attila the Hun acted in the live-action remake of Mulan.\n",
    "Output: Yes\n",
    "Input: Kurt Cobain starred in the 1990 television show \"Twin Peaks\".\n",
    "Output: Yes\"\"\"\n",
    "\n",
    "instructions = propose_instruction(instruct_prompt, io_pairs, 50)\n",
    "\n",
    "def get_anachronism_ape_fn(instruction, batch_size=10):\n",
    "#     decomposition = '1.'+ decomposition\n",
    "#     last_n = int(re.findall(r'(\\d+)\\.', decomposition)[-1])\n",
    "#     decomposition += '\\n%s. Output YES if there is an anachronism, and NO otherwise' % (last_n + 1)\n",
    "    instruction = instruction.strip()\n",
    "    def decomposition_ape_fn(sentences):\n",
    "        gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=1)\n",
    "        out = []\n",
    "        for chunk in chunks(sentences, batch_size):\n",
    "            prompts = ['''An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time. Figure out whether a sentence contains anachronisms or not, using this instruction.\n",
    "Instruction:\n",
    "%s\n",
    "----\n",
    "Sentence: %s\n",
    "Is this an Anachronism? Output YES if there is an anachronism, and NO otherwise.''' % (instruction, x) for x in chunk]\n",
    "            out.extend(gpt3(prompts))\n",
    "        return out\n",
    "    return decomposition_ape_fn\n",
    "\n",
    "labs, subset = get_subset(inputs, labels, n=100)\n",
    "all_preds = []\n",
    "pps = []\n",
    "accs = []\n",
    "for z, instruction in enumerate(instructions):\n",
    "    print('Instruction', z)\n",
    "    fn = get_anachronism_ape_fn(instruction, batch_size=20)\n",
    "    this_preds = fn(subset)\n",
    "    pp = np.array([1 if 'yes' in x.lower() else 0 for x in this_preds])\n",
    "    all_preds.append(this_preds)\n",
    "    pps.append(pp)\n",
    "    accs.append((pp==labs).mean())\n",
    "    print((pp==labs).mean())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438263eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2efca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decomposition 0\n",
      "0.55\n",
      "Decomposition 1\n",
      "0.66\n",
      "Decomposition 2\n",
      "0.59\n",
      "Decomposition 3\n",
      "0.57\n",
      "Decomposition 4\n",
      "0.54\n",
      "Decomposition 5\n",
      "0.64\n",
      "Decomposition 6\n",
      "0.6\n",
      "Decomposition 7\n",
      "0.59\n",
      "Decomposition 8\n",
      "0.66\n",
      "Decomposition 9\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "# Automatic decomposition runs\n",
    "\n",
    "decomp_prompt = 'I want to break down the task of figuring out whether a sentence contains anachronisms or not, into individual steps. An anachronism is a mistake in chronology, or a person, thing, or event that is out of its proper time.'\n",
    "decompositions = propose_decomposition(decomp_prompt, io_pairs, 10)\n",
    "\n",
    "def get_anachronism_fn(decomposition, batch_size=10):\n",
    "    decomposition = '1.'+ decomposition\n",
    "    last_n = int(re.findall(r'(\\d+)\\.', decomposition)[-1])\n",
    "#     decomposition += '\\n%s. Output YES if there is an anachronism, and NO otherwise' % (last_n + 1)\n",
    "    def decomposition_fn(sentences):\n",
    "        gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=400, quote='---', n=1)\n",
    "        out = []\n",
    "        for chunk in chunks(sentences, batch_size):\n",
    "            prompts = ['''Figure out whether a sentence contains anachronisms or not, using the following steps\n",
    "Steps:\n",
    "%s\n",
    "----\n",
    "Sentence: %s\n",
    "Is this an Anachronism? Show me how you arrived at this answer step-wise. Output YES if there is an anachronism, and NO otherwise.''' % (decomposition, x) for x in chunk]\n",
    "            out.extend(gpt3(prompts))\n",
    "        return out\n",
    "    return decomposition_fn\n",
    "\n",
    "\n",
    "labs, subset = get_subset(inputs, labels, n=100)\n",
    "preds = []\n",
    "pps = []\n",
    "accs = []\n",
    "all_preds = []\n",
    "for z, decomposition in enumerate(decompositions):\n",
    "    print('Decomposition', z)\n",
    "    fn = get_anachronism_fn(decomposition, batch_size=20)\n",
    "    this_preds = fn(subset)\n",
    "#     pp = np.array([1 if 'contains an anachronism' in x.lower() else 0 for x in this_preds])\n",
    "    pp = np.array([1 if 'yes' in x.lower() else 0 for x in this_preds])\n",
    "    preds.append(this_preds)\n",
    "    pps.append(pp)\n",
    "    accs.append((pp==labs).mean())\n",
    "    print((pp==labs).mean())\n",
    "    all_preds.append(this_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e895b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34858992",
   "metadata": {},
   "source": [
    "#### Dataset from decomposed prompting (K'th letter concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec13d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Take the letters at position 3 of the words in \"Musa Haiying Schmidt Robinson Afzal\" and concatenate them using a space.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/allenai/DecomP/main/datasets/letter_cat/n5_eg100_pos2_space.json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "inputs = [d['question'] for d in data['1']['qa_pairs']]\n",
    "labels = [d['answer']['spans'][0] for d in data['1']['qa_pairs']]\n",
    "len(data['1']['qa_pairs'])\n",
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f54c8e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual decomposition\n",
    "out = []\n",
    "batch_size = 10\n",
    "for chunk in tqdm.tqdm(chunks(inputs, batch_size)):\n",
    "    prompts = [x for x in chunk]\n",
    "#     print(prompts)\n",
    "    out.extend(gpt3(prompts))\n",
    "pp = np.array([1 if p.strip().lower() == l else 0 for p, l in zip(out, labels)])\n",
    "pp.sum()/len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5235b50",
   "metadata": {},
   "source": [
    "#### Dataset from decomposed prompting (List reversal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "820509d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "import urllib.request\n",
    "url = 'https://raw.githubusercontent.com/allenai/DecomP/main/datasets/reverse/test_10_normal_words.json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "inputs = [d['question'] for d in data['alg_qa']['qa_pairs']]\n",
    "labels = [d['answer']['spans'][0] for d in data['alg_qa']['qa_pairs']]\n",
    "# len(data['1']['qa_pairs'])\n",
    "len(data['alg_qa']['qa_pairs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "09e0afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:07,  1.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual decomposition\n",
    "out = []\n",
    "batch_size = 10\n",
    "for chunk in tqdm.tqdm(chunks(inputs, batch_size)):\n",
    "    prompts = [x for x in chunk]\n",
    "#     print(prompts)\n",
    "    out.extend(gpt3(prompts))\n",
    "pp = np.array([1 if p.strip().lower() == l else 0 for p, l in zip(out, labels)])\n",
    "pp.sum()/len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24ff32",
   "metadata": {},
   "source": [
    "#### Tasks in Self-prompt (Ofir's paper) \n",
    "Musique and 2wikimultihop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7a4f097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-a426bd25b30faa3b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /mmfs1/home/bparan/.cache/huggingface/datasets/json/default-a426bd25b30faa3b/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a69890c01842649de4b290ea7ea413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9cca8ae9704f5f95dd903dfd148506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /mmfs1/home/bparan/.cache/huggingface/datasets/json/default-a426bd25b30faa3b/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba35e393875b4e7d8eaa4dda812809e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Musique\n",
    "data_files = {split:os.path.join(cache_dir, 'musique', 'data', 'musique_full_v1.0_%s.jsonl'%split) for split in ['train', 'dev']}\n",
    "d = datasets.load_dataset('json', data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe72d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-8da56daef1cdd353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /mmfs1/home/bparan/.cache/huggingface/datasets/json/default-8da56daef1cdd353/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7d9ed1adc74809857324e91cab467a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35e6a21b430439a96a4b24e211e85f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ab5378eee44c529495b0955bcaee42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2wikimultihop\n",
    "data_files = {split:os.path.join(cache_dir, '2wikimultihop', 'data', '%s.json'%split) for split in ['train', 'dev']}\n",
    "d = datasets.load_dataset('json', data_files=data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609e970",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Known Unknown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "481840a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/known_unknowns/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52907300d76248069aac4fb1f9eb2339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "d = datasets.load_dataset('bigbench', 'known_unknowns', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e7309",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Strategy QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b5222b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/strategyqa/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c4409edab54fb885eea549518047f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "d = datasets.load_dataset('bigbench', 'strategyqa', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52893054",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Hindu Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c5610e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/hindu_knowledge/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c19a2ea665649b69c59961dfa5f3c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'hindu_knowledge', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca77d2",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Movie Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "22597433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/movie_dialog_same_or_different (download: Unknown size, generated: 54.67 MiB, post-processed: Unknown size, total: 54.67 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/movie_dialog_same_or_different/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/movie_dialog_same_or_different/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d2bd46c0594072b36d01641a96b82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'movie_dialog_same_or_different', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944af84",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - Code Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1aab6b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/code_line_description (download: Unknown size, generated: 65.91 KiB, post-processed: Unknown size, total: 65.91 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/code_line_description/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/code_line_description/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 12:55:43.847088: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02a8aac77f94358b12ad4f1d55e382a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'code_line_description', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a129bd9",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - conceptual_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "991dff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/conceptual_combinations/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8129b4b31c26403298011f3ff7125cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'conceptual_combinations', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360252f",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - language_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b2dd6f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/language_identification (download: Unknown size, generated: 14.10 MiB, post-processed: Unknown size, total: 14.10 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/language_identification/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/language_identification/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930f17d5643143e4a7b5c86c2cb34a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'language_identification', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8a49e",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - vitaminc_fact_verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "836e1fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/vitaminc_fact_verification/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c52b29c5a7456d8ecf79b03ee0180c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'vitaminc_fact_verification', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d38587",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - formal_fallacies_syllogisms_negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cfeb4a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/formal_fallacies_syllogisms_negation (download: Unknown size, generated: 15.87 MiB, post-processed: Unknown size, total: 15.87 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/formal_fallacies_syllogisms_negation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/14200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/formal_fallacies_syllogisms_negation/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a00e4057ef4968b66e0cc6f31436a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'formal_fallacies_syllogisms_negation', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b054c",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - misconceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "93047143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/misconceptions (download: Unknown size, generated: 89.72 KiB, post-processed: Unknown size, total: 89.72 KiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/misconceptions/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/219 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/176 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/43 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/misconceptions/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc80bd94e396417b9bccc866a91c8747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'misconceptions', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "45f4c714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based only on the information contained in a brief quote from Wikipedia, answer whether the related claim is True, False or Neither. Use Neither when the Wikipedia quote does not provide the necessary information to resolve the question.\\n\\n\\nPassage: Garfield-COLON- A Tail of Two Kitties: The film received negative reviews from critics and it earned $ 141.7 million on a $ 60 million budget.\\nClaim: Garfield : A Tail of Two Kitties received bleak reviews .\\nTrue, False, or Neither?'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5f7d4",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - logical_deduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3fc3a542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/winowhy (download: Unknown size, generated: 1.91 MiB, post-processed: Unknown size, total: 1.91 MiB) to /gscratch/zlab/bparan/projects/cascades/data/bigbench/winowhy/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/2862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: winowhy has 3 duplicate examples out of 2865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/572 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /gscratch/zlab/bparan/projects/cascades/data/bigbench/winowhy/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a2ad57c94c4f94a238fe5eccb8da46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'logical_deduction', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a5992",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - winowhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "da6eed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/winowhy/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc03f098400d447ea13ffd65d7dd1d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'winowhy', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7701571",
   "metadata": {},
   "source": [
    "#### Tasks in Flipped learning - novel_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1eb49750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset bigbench (/gscratch/zlab/bparan/projects/cascades/data/bigbench/novel_concepts/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac37fea13074cf1867ad1b073983002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'novel_concepts', cache_dir=cache_dir)\n",
    "inputs = d['train']['inputs'] + d['validation']['inputs']\n",
    "# inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = d['train']['targets'] + d['validation']['targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb352fb",
   "metadata": {},
   "source": [
    "#### Tasks in Auto-Cot - MAWPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9672b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration omarxadel--MaWPS-ar-e0d2ee7eb9fa6fdb\n",
      "WARNING:datasets.builder:Found cached dataset csv (/gscratch/zlab/bparan/projects/cascades/data/omarxadel___csv/omarxadel--MaWPS-ar-e0d2ee7eb9fa6fdb/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdea24f74c842a883de210717448f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('omarxadel/MaWPS-ar', 'test', cache_dir=cache_dir)\n",
    "inputs = [list(d.values())[0] for d in data['validation']]\n",
    "labels = []\n",
    "for d in data['validation']:\n",
    "    try:\n",
    "        ans = eval(list(d.values())[1].split(\"=\")[-1].strip())\n",
    "        if isinstance(ans, int):\n",
    "            labels.append(ans)\n",
    "        elif (ans).is_integer():\n",
    "            labels.append(int(ans))\n",
    "        else:\n",
    "            labels.append(float(\"%.2f\" % ans))\n",
    "        \n",
    "    except:\n",
    "        ans = eval(list(d.values())[1].split(\"=\")[0].strip())\n",
    "        if isinstance(ans, int):\n",
    "            labels.append(ans)\n",
    "        elif (ans).is_integer():\n",
    "            labels.append(int(ans))\n",
    "        else:\n",
    "            labels.append(float(\"%.2f\" % ans))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb1018",
   "metadata": {},
   "source": [
    "#### Tasks in Auto-CoT (GSM8K) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "905a872a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset gsm8k (/gscratch/zlab/bparan/projects/cascades/data/gsm8k/main/1.1.0/37bfb08b1d4fcbb01f06b03d9e1ef5f1fcbd4d3af3d08842c50d7305091285ba)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4a5d9f0d184caca424c0d917152c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('gsm8k', 'main', cache_dir=cache_dir)['test']\n",
    "inputs = [d['question'] for d in data]\n",
    "labels = [d['answer'].split('#### ')[-1] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d15aa",
   "metadata": {},
   "source": [
    "#### Tasks on Auto-CoT (AQUA-RAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "37271355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset aqua_rat (/gscratch/zlab/bparan/projects/cascades/data/aqua_rat/raw/0.0.0/fc47b9f437236ab96fc1fcb61096aa193819aedd76437893e2390ab0740a3381)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e6777075404d81981fe5fedca07100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('aqua_rat', 'raw', cache_dir=cache_dir)['validation']\n",
    "inputs = [d['question'] + \" \".join(d['options']) for d in data]\n",
    "labels = [d['correct'] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5806b68",
   "metadata": {},
   "source": [
    "#### Tasks on Auto-CoT (Commonsense QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "97fd3146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset commonsense_qa (/gscratch/zlab/bparan/projects/cascades/data/commonsense_qa/default/1.0.0/28d68f56649a7f0c23bc68eae850af914aa03f95f810011ae8cf58cc5ff5051b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04b0e80a4ab497b899bcde76407b7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_dataset('commonsense_qa', cache_dir=cache_dir)['validation']\n",
    "inputs = [d['question']+ \" \" + \" \".join([k + \") \" + v for k, v in zip(d['choices']['label'], d['choices']['text'])]) for d in data]\n",
    "labels = [d['answerKey'] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc76bad",
   "metadata": {},
   "source": [
    "#### AMA Tasks (From Super-Glue they include boolQ, cb, copa, multirc, record, rte, wsc, WiC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a1aa117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset super_glue (/gscratch/zlab/bparan/projects/cascades/data/super_glue/boolq/1.0.3/bb9675f958ebfee0d5d6dc5476fafe38c79123727a7258d515c450873dbdbbed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612959773ee240b6aaec658ef258da4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BoolQ\n",
    "data = datasets.load_dataset('super_glue', 'boolq', cache_dir=cache_dir)['validation']\n",
    "inputs = [d['passage']+ \" \" + d['question'][0].title() + d['question'][1:]  + \"?\" for d in data]\n",
    "label_dict = {0:'False', 1:'True'}\n",
    "labels = [label_dict[d['label']] for d in data]\n",
    "# Similar transformations to be made for other Superglue tasks: cb, copa, multirc, record, rte, wsc, wic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00945a0",
   "metadata": {},
   "source": [
    "#### AMA Tasks (From Adversarial NLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "99c0f9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset anli (/gscratch/zlab/bparan/projects/cascades/data/anli/plain_text/0.1.0/aabce88453b06dff21c201855ea83283bab0390bff746deadb30b65695755c0b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70388adbb624042b83e317439e0d841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Can also look at dev_r2, dev_r2\n",
    "data = datasets.load_dataset('anli', cache_dir=cache_dir)['dev_r3']\n",
    "inputs = [\"Sentence1: \" + d['premise'] + \"\\nSentence2: \" +d['hypothesis'] for d in data]\n",
    "label_dict = {0:\"entailment\", 1:'neutral', 2:'contradiction'}\n",
    "labels = [label_dict[d['label']] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a228ef",
   "metadata": {},
   "source": [
    "#### Flipped Learning tasks Storycloze, PIQA, HellaSwag, ARC challenge and openbookQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "30047099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-fe6cd1e9646dcb63\n",
      "WARNING:datasets.builder:Found cached dataset story_cloze (/mmfs1/home/bparan/.cache/huggingface/datasets/story_cloze/default-fe6cd1e9646dcb63/0.0.0/45cead0538c3deb72d731a7990e60835c2c9c5d5d5b1e95a7dd47ccf593671e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23454a81d8e34b038819326c5ed3630a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1571"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# story_cloze\n",
    "validation_path = os.path.join(cache_dir, 'story_cloze') #, 'cloze_test_val__winter2018-cloze_test_ALL_val - 1 - 1.csv')\n",
    "data = datasets.load_dataset('story_cloze', data_dir=validation_path)\n",
    "len(data['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b52c0d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset piqa (/gscratch/zlab/bparan/projects/cascades/data/piqa/plain_text/1.1.0/6c611c1a9bf220943c4174e117d3b660859665baf1d43156230116185312d011)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a4f1648a394155ab6604516c08e4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'goal': \"How do I ready a guinea pig cage for it's new occupants?\",\n",
       " 'sol1': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped paper strips, you will also need to supply it with a water bottle and a food dish.',\n",
       " 'sol2': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped jeans material, you will also need to supply it with a water bottle and a food dish.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_dataset('piqa', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5fc0cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset hellaswag (/gscratch/zlab/bparan/projects/cascades/data/hellaswag/default/0.1.0/c37cd37196278995f42bc32f532730ae9b0d5f0f4a2d3b97735c17ff3ad67169)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be88dd9dbb4b49e2b2b1064d3c7dd61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ind': 24,\n",
       " 'activity_label': 'Roof shingle removal',\n",
       " 'ctx_a': 'A man is sitting on a roof.',\n",
       " 'ctx_b': 'he',\n",
       " 'ctx': 'A man is sitting on a roof. he',\n",
       " 'endings': ['is using wrap to wrap a pair of skis.',\n",
       "  'is ripping level tiles off.',\n",
       "  \"is holding a rubik's cube.\",\n",
       "  'starts pulling up roofing on a roof.'],\n",
       " 'source_id': 'activitynet~v_-JhWjGDPHMY',\n",
       " 'split': 'val',\n",
       " 'split_type': 'indomain',\n",
       " 'label': '3'}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_dataset('hellaswag', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b91b1809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset ai2_arc (/gscratch/zlab/bparan/projects/cascades/data/ai2_arc/ARC-Challenge/1.0.0/1569c2591ea2683779581d9fb467203d9aa95543bb9b75dcfde5da92529fd7f6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b2a5d2f659495ab5853e9ab4c2cd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_407695',\n",
       " 'question': 'Juan and LaKeisha roll a few objects down a ramp. They want to see which object rolls the farthest. What should they do so they can repeat their investigation?',\n",
       " 'choices': {'text': ['Put the objects in groups.',\n",
       "   'Change the height of the ramp.',\n",
       "   'Choose different objects to roll.',\n",
       "   'Record the details of the investigation.'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'D'}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is also the ARC-easy split\n",
    "data = datasets.load_dataset('ai2_arc', 'ARC-Challenge', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a7ff7443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset openbookqa (/gscratch/zlab/bparan/projects/cascades/data/openbookqa/main/1.0.1/f338ccacfbc86fb8c2de3aa1c06d2ce686933de3bca284dba97d32592c52b33f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4d5d19360f4086a4958154069fcb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '8-376',\n",
       " 'question_stem': 'Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as',\n",
       " 'choices': {'text': ['Deep sea animals',\n",
       "   'fish',\n",
       "   'Long Sea Fish',\n",
       "   'Far Sea Animals'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'A'}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenbookQa\n",
    "data = datasets.load_dataset('openbookqa', 'main', cache_dir=cache_dir)['validation']\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee02beb",
   "metadata": {},
   "source": [
    "#### Other tasks from AMA (Classification) : Agnews, DBPedia, Amazon movie reivew and SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "06a0c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default\n",
      "WARNING:datasets.builder:Found cached dataset ag_news (/gscratch/zlab/bparan/projects/cascades/data/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0758b6a13674b6b9deaf0514cd78d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## For others use the strings : dbpedia_14, sst2\n",
    "data = datasets.load_dataset('ag_news', cache_dir=cache_dir)['test']\n",
    "inputs = [d['text'] for d in data]\n",
    "label_dict = {0:'World', 1:'Sports', 2:'Business', 3: 'Sci/Tech'}\n",
    "labels = [label_dict[d['label']] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c7839",
   "metadata": {},
   "source": [
    "#### Tasks from reframing natural language instructions\n",
    "\n",
    "MC-Taco (question generation), QASC (question generation), Quoref, Winogrande, CosmosQA, MultiRC, MC-TACO (Incorrect answer generation for duration and transcience questions), QASC (overlapping words), Essential terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "89ea8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download natural instructions\n",
    "\n",
    "def transform_example(example):\n",
    "    # Very simple transformation of the example\n",
    "    return example[\"input\"] + \"\\n\" + example[\"output\"]\n",
    "\n",
    "NQ_REWRITE_TASKS = ['task003_mctaco_question_generation_event_duration.json', \n",
    "           'task040_qasc_question_generation.json',\n",
    "           'task002_quoref_answer_generation.json',\n",
    "           'task033_winogrande_answer_generation.json',\n",
    "           'task024_cosmosqa_answer_generation.json',\n",
    "           'task056_multirc_classify_correct_answer.json',\n",
    "           'task005_mctaco_wrong_answer_generation_event_duration.json', \n",
    "           'task008_mctaco_wrong_answer_generation_transient_stationary.json',\n",
    "           'task039_qasc_find_overlapping_words.json',\n",
    "           'task044_essential_terms_identifying_essential_words.json']\n",
    "for task_name in NQ_REWRITE_TASKS:\n",
    "    nq_path = \"/mmfs1/gscratch/zlab/bparan/projects/cascades/src/natural-instructions/tasks\"\n",
    "    task_path = os.path.join(nq_path, task_name)\n",
    "    task_data = json.loads(open(task_path).read())\n",
    "    instances = []\n",
    "    for instance in task_data[\"Instances\"]:\n",
    "        instances.append({\"guid\": instance['id'], \"input\": instance[\"input\"], \"label\": instance[\"output\"][0]})\n",
    "    instruction = task_data[\"Definition\"]\n",
    "    examples = \"\"\n",
    "    for ex in task_data[\"Positive Examples\"]:\n",
    "        examples += transform_example(ex)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd0b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Additional promising datasets from BigBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297c6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
