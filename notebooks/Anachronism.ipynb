{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fa9ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "with open(os.path.expanduser('~/.openai_api_key'), 'r') as file:\n",
    "    openai.api_key = file.read().replace('\\n', '')\n",
    "\n",
    "import adatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c7826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset bigbench/anachronisms (download: Unknown size, generated: 95.60 KiB, post-processed: Unknown size, total: 95.60 KiB) to /home/marcotcr/.cache/huggingface/datasets/bigbench/anachronisms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating default split:   0%|          | 0/230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 09:09:23.645979: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/opencv-3.1.0/lib:/usr/local/cuda-10.0/lib64:/usr/lib/x86_64-linux-gnu/openmpi/lib/\n",
      "2022-09-30 09:09:23.646048: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/opencv-3.1.0/lib:/usr/local/cuda-10.0/lib64:/usr/lib/x86_64-linux-gnu/openmpi/lib/\n",
      "2022-09-30 09:09:23.646089: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/opencv-3.1.0/lib:/usr/local/cuda-10.0/lib64:/usr/lib/x86_64-linux-gnu/openmpi/lib/\n",
      "2022-09-30 09:09:23.646130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/opencv-3.1.0/lib:/usr/local/cuda-10.0/lib64:/usr/lib/x86_64-linux-gnu/openmpi/lib/\n",
      "2022-09-30 09:09:23.646169: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/opencv-3.1.0/lib:/usr/local/cuda-10.0/lib64:/usr/lib/x86_64-linux-gnu/openmpi/lib/\n",
      "2022-09-30 09:09:23.646207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/opencv-3.1.0/lib:/usr/local/cuda-10.0/lib64:/usr/lib/x86_64-linux-gnu/openmpi/lib/\n",
      "2022-09-30 09:09:23.646249: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/opencv-3.1.0/lib:/usr/local/cuda-10.0/lib64:/usr/lib/x86_64-linux-gnu/openmpi/lib/\n",
      "2022-09-30 09:09:23.646287: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib:/usr/local/opencv-3.1.0/lib:/usr/local/cuda-10.0/lib64:/usr/lib/x86_64-linux-gnu/openmpi/lib/\n",
      "2022-09-30 09:09:23.646295: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-30 09:09:23.646554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/46 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bigbench downloaded and prepared to /home/marcotcr/.cache/huggingface/datasets/bigbench/anachronisms/1.0.0/7d2f6e537fa937dfaac8b1c1df782f2055071d3fd8e4f4ae93d28012a354ced0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b5d63339814e63904284fed85832eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = datasets.load_dataset('bigbench', 'anachronisms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c92cf424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "inputs = d['validation']['inputs']\n",
    "inputs = [x.split('\\n')[0] for x in inputs]\n",
    "labels = np.array([int(x[0] == 'Yes') for x in d['validation']['targets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8b068223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d['validation']['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "087b3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIModel(adatest.Model):\n",
    "    def __init__(self, model=\"text-davinci-002-\", quote=\"\\\"\", temperature=0.7, top_p=1, max_length=30, n=1):\n",
    "        self.model = model\n",
    "        self.api_key = openai.api_key\n",
    "        self.quote = quote\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.max_length = max_length\n",
    "        self.n = n\n",
    "    def __call__(self, strings):\n",
    "        resp = openai.Completion.create(\n",
    "            model=self.model,\n",
    "            prompt=strings,\n",
    "            max_tokens=self.max_length,\n",
    "            temperature=self.temperature,\n",
    "            top_p=self.top_p,\n",
    "            n=self.n,\n",
    "            stop=self.quote,\n",
    "        )\n",
    "        return [x[\"text\"] for x in resp['choices']]\n",
    "\n",
    "gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=200, quote='', n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe60a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anachronism(x):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=200, quote='---', n=1)\n",
    "    prompt = '''Given a sentence and the time periods of each entity in it, tell me if it could have happened or not.\n",
    "Sentence: I wrote about shakespeare\n",
    "Entities and dates:\n",
    "I -> 21st century\n",
    "Shakespeare -> 16th century\n",
    "Could the sentence be true based on the dates alone: Yes\n",
    "----\n",
    "Sentence: Shakespeare wrote about me\n",
    "\n",
    "Entities and dates:\n",
    "Shakespeare -> 16th century\n",
    "I -> 21st century\n",
    "\n",
    "Could the sentence be true based on the dates alone: No\n",
    "----\n",
    "Sentence: %s''' % x\n",
    "    return gpt3(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1feb73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anachronismv2(x):\n",
    "    gpt3 = OpenAIModel(model=\"text-davinci-002\",  max_length=200, quote='---', n=1)\n",
    "    prompt = '''Given a sentence tell me if it could have happened or not based on the time periods of the entities.\n",
    "Sentence: I wrote about shakespeare\n",
    "Could the sentence be true based on the time periods alone: Yes\n",
    "----\n",
    "Sentence: Shakespeare wrote about me\n",
    "Could the sentence be true based on the time periods alone: No\n",
    "----\n",
    "Sentence: %s''' % x\n",
    "    return gpt3(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4f83326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anachronismv3(x):\n",
    "    prompt = '''Given a sentence, extract the entities and their relationships, and tell me if they are anachronistic.\n",
    "Sentence: I wrote about shakespeare\n",
    "Relationships:\n",
    "- (I, write about, shakespeare) -> not anachronistic, \n",
    "----\n",
    "Sentence: Shakespeare wrote about me\n",
    "Relationships:\n",
    "- (shakespeare, write about, me) -> anachronistic\n",
    "----\n",
    "Sentence: The builders of the pyramids at Giza listened to jazz during their break.\n",
    "Relationships:\n",
    "- (builders, listen to, jazz) -> anachronistic\n",
    "----\n",
    "Sentence: %s\n",
    "''' % x\n",
    "    return gpt3(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e258d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for x in inputs:\n",
    "    answers.append(anachronism(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ec813d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers2 = []\n",
    "for x in inputs:\n",
    "    answers2.append(anachronismv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da8d2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answers3 = []\n",
    "for x in inputs:\n",
    "    answers3.append(anachronismv3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c30ba4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([int(x[0].endswith('No')) for x in answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7ed322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = np.array([int(x[0].endswith('No')) for x in answers2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f79ee80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds3 = np.array([1 - int('not anachronistic' in x[0]) for x in answers3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5af220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7391304347826086"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af288166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6956521739130435"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds2 == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32720d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6304347826086957"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds3 == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd2f14a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jason, the first person to explore the ancient pyramid in over 2000 years, opened a sealed box inside and found a floppy disk.\n",
      "\n",
      "\n",
      "Jason -> 21st century\n",
      "ancient pyramid -> ?\n",
      "\n",
      "Could the sentence be true based on the dates alone:\n",
      "\n",
      "The sentence could be true if the ancient pyramid is from the 21st century.\n",
      "1\n",
      "----\n",
      "The first ever movie in color depicted the life of Sacagawea.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "The first ever movie in color -> late 19th century\n",
      "Sacagawea -> late 18th century - early 19th century\n",
      "\n",
      "Could the sentence be true based on the dates alone: No\n",
      "0\n",
      "----\n",
      "Jason, while exploring an ancient pyramid, opened a sealed box inside and found a floppy disk.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "Jason -> 21st century\n",
      "floppy disk -> 1970s-2000s\n",
      "\n",
      "Could the sentence be true based on the dates alone: No\n",
      "0\n",
      "----\n",
      "During their meetings in Bali, George Washington and the delegate of the Tokugawa shogunate exchanged gifts.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "George Washington -> 18th century\n",
      "Tokugawa shogunate -> 17th century\n",
      "\n",
      "Could the sentence be true based on the dates alone: No\n",
      "0\n",
      "----\n",
      "Donnie Yen the martial artist acted in the live-action remake of Mulan.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "Donnie Yen -> 20th century\n",
      "Mulan -> 6th century\n",
      "\n",
      "Could the sentence be true based on the dates alone: No\n",
      "0\n",
      "----\n",
      "The appearance of prokaryotes on Earth coincided with the formation of the moon.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "Prokaryotes -> 3.5 billion years ago\n",
      "Earth -> 4.5 billion years ago\n",
      "Moon -> 4.5 billion years ago\n",
      "\n",
      "Could the sentence be true based on the dates alone: Yes\n",
      "1\n",
      "----\n",
      "The sun's creation during the early universe is the cause of its size, color, and brightness.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "The sun -> 4.6 billion years ago\n",
      "The early universe -> 13.8 billion years ago\n",
      "\n",
      "Could the sentence be true based on the dates alone: Yes\n",
      "1\n",
      "----\n",
      "The emperor rode his Ferrari to the Coliseum.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "Emperor -> 1st century\n",
      "Ferrari -> 21st century\n",
      "Coliseum -> 1st century\n",
      "\n",
      "Could the sentence be true based on the dates alone: No\n",
      "0\n",
      "----\n",
      "Having broken Enigma Machine encryption, the Allies were able to map enemy movement through the trenches of Passchendaele.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "Enigma Machine -> 20th century\n",
      "Allies -> 20th century\n",
      "Passchendaele -> 20th century\n",
      "\n",
      "Could the sentence be true based on the dates alone: Yes\n",
      "1\n",
      "----\n",
      "The US senator used her vote to help pass the Wade-Davis bill.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "US senator -> 1864\n",
      "Wade-Davis bill -> 1864\n",
      "\n",
      "Could the sentence be true based on the dates alone: Yes\n",
      "1\n",
      "----\n",
      "When scientists found the female Australopithecus afarensis, AL 288-1, they named her Rosa Parks after the Outkast song.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "\n",
      "Scientists -> 20th century\n",
      "Rosa Parks -> 20th century\n",
      "Outkast -> 20th century\n",
      "\n",
      "Could the sentence be true based on the dates alone: Yes\n",
      "1\n",
      "----\n",
      "Vasco de Gama avoided shipwreck by the Cape of Good Hope thanks to his astrolabe.\n",
      "\n",
      "\n",
      "Entities and dates:\n",
      "Vasco de Gama -> 15th century\n",
      "Cape of Good Hope -> 15th century\n",
      "Astrolabe -> 2nd century\n",
      "\n",
      "Could the sentence be true based on the dates alone: No\n",
      "0\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for x in np.where(preds != labels)[0]:\n",
    "    print(inputs[x])\n",
    "    print(answers[x][0])\n",
    "    print(labels[x])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b96e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adatest",
   "language": "python",
   "name": "adatest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
