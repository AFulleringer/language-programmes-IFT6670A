@inproceedings{cohan-etal-2018-discourse,
  address   = {New Orleans, Louisiana},
  author    = {Cohan, Arman and Dernoncourt, Franck and Kim, Doo Soon and Bui, Trung and Kim, Seokhwan and Chang, Walter and Goharian, Nazli},
  booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
  doi       = {10.18653/v1/N18-2097},
  month     = {jun},
  pages     = {615-621},
  publisher = {Association for Computational Linguistics},
  title     = {A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents},
  url       = {https://aclanthology.org/N18-2097},
  year      = {2018},
}

@article{ganesan2015rouge,
  author  = {Kavita A. Ganesan},
  journal = {arXiv preprint arXiv: Arxiv-1803.01937},
  title   = {ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization Tasks},
  year    = {2015},
}

@inproceedings{lin-hovy-2003-automatic,
  author    = {Lin, Chin-Yew  and
               Hovy, Eduard},
  booktitle = {Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics},
  pages     = {150--157},
  title     = {Automatic Evaluation of Summaries Using N-gram Co-occurrence Statistics},
  url       = {https://aclanthology.org/N03-1020},
  year      = {2003},
}

@article{paranjape2023art,
  author  = {Bhargavi Paranjape and Scott Lundberg and Sameer Singh and Hannaneh Hajishirzi and Luke Zettlemoyer and Marco Tulio Ribeiro},
  journal = {arXiv preprint arXiv: Arxiv-2303.09014},
  title   = {ART: Automatic multi-step reasoning and tool-use for large language models},
  year    = {2023},
}

@misc{schick2023toolformer,
      title={Toolformer: Language Models Can Teach Themselves to Use Tools}, 
      author={Timo Schick and Jane Dwivedi-Yu and Roberto Dessì and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
      year={2023},
      eprint={2302.04761},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wei2023chainofthought,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{kojima2023large,
      title={Large Language Models are Zero-Shot Reasoners}, 
      author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
      year={2023},
      eprint={2205.11916},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{imani2023mathprompter,
      title={MathPrompter: Mathematical Reasoning using Large Language Models}, 
      author={Shima Imani and Liang Du and Harsh Shrivastava},
      year={2023},
      eprint={2303.05398},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shuster2022language,
      title={Language Models that Seek for Knowledge: Modular Search & Generation for Dialogue and Prompt Completion}, 
      author={Kurt Shuster and Mojtaba Komeili and Leonard Adolphs and Stephen Roller and Arthur Szlam and Jason Weston},
      year={2022},
      eprint={2203.13224},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{pang2022long,
      title={Long Document Summarization with Top-down and Bottom-up Inference}, 
      author={Bo Pang and Erik Nijkamp and Wojciech Kryściński and Silvio Savarese and Yingbo Zhou and Caiming Xiong},
      year={2022},
      eprint={2203.07586},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{guo2022longt5,
      title={LongT5: Efficient Text-To-Text Transformer for Long Sequences}, 
      author={Mandy Guo and Joshua Ainslie and David Uthus and Santiago Ontanon and Jianmo Ni and Yun-Hsuan Sung and Yinfei Yang},
      year={2022},
      eprint={2112.07916},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{phang2022investigating,
      title={Investigating Efficiently Extending Transformers for Long Input Summarization}, 
      author={Jason Phang and Yao Zhao and Peter J. Liu},
      year={2022},
      eprint={2208.04347},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}